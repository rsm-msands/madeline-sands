[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Madeline Sands",
    "section": "",
    "text": "Welcome to my website!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Madeline Sands",
    "section": "",
    "text": "Madeline is the Senior Category Data Manager at Scientist.com and Data Scientist. When not learning about machine learning and natural language processing, she enjoys spending time road and mountain biking, throwing pottery, and being outside."
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "My Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "projects/project1/projects_files/mediabag/index.html",
    "href": "projects/project1/projects_files/mediabag/index.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe goal of their project was to test the effectiveness of a matching grant on chartiable giving. Via their large-scale natural field experiment, they found that providing a match offer increases both the charitable revenue per solicitation and the response rate to the letters. However, the larger amount of the match ratio, (i.e. $3:$1 and $2:$1), relative to a smaller match ratio, ($1:$1), had no additional impact on the revenue per solicitation nor the response rate to the letter.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\n\n\nMadeline Sands\n\n\nMay 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nPoisson Regression Examples\n\n\n\n\n\n\nMadeline Sands\n\n\nMay 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/project1/projects_files/mediabag/index.html#introduction",
    "href": "projects/project1/projects_files/mediabag/index.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe goal of their project was to test the effectiveness of a matching grant on chartiable giving. Via their large-scale natural field experiment, they found that providing a match offer increases both the charitable revenue per solicitation and the response rate to the letters. However, the larger amount of the match ratio, (i.e. $3:$1 and $2:$1), relative to a smaller match ratio, ($1:$1), had no additional impact on the revenue per solicitation nor the response rate to the letter.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/project1/projects_files/mediabag/index.html#data",
    "href": "projects/project1/projects_files/mediabag/index.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nimport numpy as np \nimport pandas as pd \nfrom scipy.stats import t\nfrom scipy.stats import ttest_ind\n\nkarlan_df = pd.read_stata('data/karlan_list_2007.dta')\n\n\nDescription\nBelow is a general overview of the data from Karlan et. al 2007. A sample of approximately 50,000 individuals who had given to a charitable organization since 1991 were randomized and assigned into either a “match” treatment group or a control group. The treatment group was offered a matching grant conditional on their donation, with the goal to see if the match rate increases the likelihood of a donation in a charitable setting. This dataset contains information such as if the participant was part of the treatment or control, the match ratio, and the size of the donation, in addition to further characteristics about the donor and the donation they made.\n\nkarlan_df.describe()\n\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio2\nratio3\nsize25\nsize50\nsize100\nsizeno\naskd1\naskd2\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\ncount\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n...\n49978.000000\n49978.000000\n48217.000000\n48047.000000\n48217.000000\n48221.000000\n48209.000000\n48214.000000\n48215.000000\n48217.000000\n\n\nmean\n0.666813\n0.333187\n0.222311\n0.222211\n0.166723\n0.166623\n0.166723\n0.166743\n0.222311\n0.222291\n...\n0.510245\n0.488715\n0.819599\n0.086710\n0.321694\n2.429012\n54815.700533\n0.669418\n0.391661\n0.871968\n\n\nstd\n0.471357\n0.471357\n0.415803\n0.415736\n0.372732\n0.372643\n0.372732\n0.372750\n0.415803\n0.415790\n...\n0.499900\n0.499878\n0.168561\n0.135868\n0.103039\n0.378115\n22027.316665\n0.193405\n0.186599\n0.258654\n\n\nmin\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.009418\n0.000000\n0.000000\n0.000000\n5000.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.755845\n0.014729\n0.258311\n2.210000\n39181.000000\n0.560222\n0.235647\n0.884929\n\n\n50%\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n0.000000\n0.872797\n0.036554\n0.305534\n2.440000\n50673.000000\n0.712296\n0.373744\n1.000000\n\n\n75%\n1.000000\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n1.000000\n0.938827\n0.090882\n0.369132\n2.660000\n66005.000000\n0.816798\n0.530036\n1.000000\n\n\nmax\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n...\n1.000000\n1.000000\n1.000000\n0.989622\n0.997544\n5.270000\n200001.000000\n1.000000\n1.000000\n1.000000\n\n\n\n\n8 rows × 48 columns\n\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of their randomization mechanism, I have provided a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically different from one another.\nI have created a function called t_test_calc that calculates the t-statistic and the p-value to determine if there is a statistically signigicant difference between the variables in the treatment and test groups at a pre-determined confidence interval.\n\ndef t_test_calc(data, treatment_col, control_col, outcome_col):\n    treatment = data[data[treatment_col] == 1]\n    control = data[data[control_col] == 1]\n    mean_treatment = treatment[outcome_col].mean()\n    mean_control = control[outcome_col].mean()\n    diff_means = mean_treatment - mean_control\n    std_treatment = treatment[outcome_col].std()\n    std_control = control[outcome_col].std()\n    n_treatment = treatment[outcome_col].count()\n    n_control = control[outcome_col].count()\n    t_stat = diff_means / np.sqrt((std_treatment**2/n_treatment) + (std_control**2/n_control))\n\n    return t_stat, n_treatment, n_control\n### T-stat calculation for mrm2 Variable###\nt_stat_mrm2, n_treatment, n_control = t_test_calc(karlan_df, \"treatment\", \"control\", \"mrm2\")\ndof = n_treatment + n_control - 2\n\np_value1 = (1 - t.cdf(np.abs(t_stat_mrm2), dof)) * 2\n\nprint(f\"t-stat calculated for mrm2: {t_stat_mrm2:.4f}\")\nprint(f\"p-value calculated for mrm2: {p_value1:.4f}\")\n\n### T-stat calculation for Freq Variable###\nt_stat_freq, n_treatment, n_control = t_test_calc(karlan_df, \"treatment\", \"control\", \"freq\")\ndof_freq = n_treatment + n_control - 2\n\np_value_freq = (1 - t.cdf(np.abs(t_stat_freq), dof)) * 2\n\nprint(f\"t-stat calculated for freq: {t_stat_freq:.4f}\")\nprint(f\"p-value calculated for freq:{p_value_freq:.4f}\")\n\nt-stat calculated for mrm2: 0.1195\np-value calculated for mrm2: 0.9049\nt-stat calculated for freq: -0.1108\np-value calculated for freq:0.9117\n\n\n\n##Linear regression for mrm2 and Freq variables\nfrom sklearn.linear_model import LinearRegression\nkarlan_df.fillna({\"mrm2\": 0}, inplace=True)\n\nX = karlan_df[['treatment']]  # Feature\ny = karlan_df['mrm2']  # Target variable\n\nmodel = LinearRegression()\nmodel.fit(X, y)\n\nprint('Coefficients for mrm2:', model.coef_)\nprint('Intercept for mrm2:', model.intercept_)\n\nCoefficients for mrm2: [0.01329623]\nIntercept for mrm2: 12.99814226643495\n\n\nAbove, I have tested the variable mrm2 & freq to see if there is a statistically significant difference between the treatment and control groups at a 95% confidence interval level. The variables mrm2 and freq represent the Number of Months since last donation and the number of prior dontations, respectively. Using the t-test-calc function, the calculated t-stat for mrm2 is 0.1195 and the p-value is 0.9049. This p-value is greater than the alpha value of 0.005, which means that we fail to reject the null hypothesis, and indicates that there is not enough evidence to conclude a statistically significant difference between the treatment and control groups when examining the number of months since their last donation, or the mrm2 variable.\nFor the freq variable, the t_stat and p_value calculated were -0.1108 and 0.9117, respectively. The calculated p-value of 0.9117 is greater than the alpha value of 0.05, and we once again fail to reject the null hypothesis. This indicates that there is not enough evidence to indicate a statistically significant difference between the treatment and control groups when comparing the donation frequency. These values are similar to those included in table 1 of Karlan et al. I believe table 1 was included in the paper to show the sample statistics of the member activity, census demographics and the state-level activity of organization."
  },
  {
    "objectID": "projects/project1/projects_files/mediabag/index.html#simulation-experiment",
    "href": "projects/project1/projects_files/mediabag/index.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\np_control = 0.018\np_treatment = 0.022\n\nnum_draws = 10000\n\ncumulative_average = np.zeros(num_draws)\ntotal_difference = 0\n\nfor i in range(num_draws):\n    control_draw = np.random.binomial(1, p_control)\n    treatment_draw = np.random.binomial(1, p_treatment)\n    difference = treatment_draw - control_draw\n    total_difference += difference\n    cumulative_average[i] = total_difference / (i + 1)\n\n\nplt.plot(cumulative_average, color='blue')\nplt.axhline(y=p_treatment - p_control, color='red', linestyle='--', label='True Difference')\nplt.xlabel('Number of Draws')\nplt.ylabel('Cumulative Average of Difference')\nplt.title('Cumulative Average of Difference in Proportions')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nAs evident in the graph, as the number of draws increases, the cumulative average of the difference in proportions becomes more stable and approaches the true difference in means. This demonstrates that as the sample size becomes larger, the estimate of the difference in means becomes more accurate and reliable. Therefore, as the sample size increases, the random sampling variability decreases, which indicates that the larger samples provide more precise estimates of population parameters and allows statisticians to make more explicit causal claims in experimentation. (assuming that all other statistical theories are upheld)\n\n\nCentral Limit Theorem\n\np_control = 0.018\np_treatment = 0.022\n\n\nsample_sizes = [50, 200, 500, 1000]\nnum_simulations = 1000\n\naverage_differences = {}\n\nfor n in sample_sizes:\n    average_differences[n] = []\n    for _ in range(num_simulations):\n        control_draws = np.random.binomial(1, p_control, size=n)\n        treatment_draws = np.random.binomial(1, p_treatment, size=n)\n        average_difference = np.mean(treatment_draws) - np.mean(control_draws)\n        average_differences[n].append(average_difference)\n\nplt.figure(figsize=(12, 8))\nfor i, n in enumerate(sample_sizes):\n    plt.subplot(2, 2, i+1)\n    plt.hist(average_differences[n], bins=30, color='blue', alpha=0.7, orientation='horizontal')\n    plt.ylabel('Average Difference')\n    plt.xlabel('Frequency')\n    plt.title(f'Sample Size = {n}')\n    plt.axhline(y=0, color='red', linestyle='--')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThe histograms show the distribution of sample averages, which are the averages of a large number of samples taken from the population. According to the Central Limit Theorem, regardless of the shape of the population distribution, the distribution of sample averages tends to be normal (bell-shaped) as the sample size increases.\nIn a normal distribution, the mean (average) is located at the center of the distribution. As we increase the sample size, the distribution of sample averages becomes increasingly normal, and the mean of this distribution approaches the true population mean. Since we’re plotting the distribution of sample averages, and zero represents the mean difference (which would be the population mean difference if the samples were large enough), it’s expected that zero would be located in the center or “middle” of the distribution.\nTherefore, in the histograms representing the Central Limit Theorem, zero typically represents the “middle” of the distribution. As the sample size increases, the distribution becomes more concentrated around zero, indicating that the sample averages are more likely to be close to the true population mean difference."
  },
  {
    "objectID": "projects/project1/projects_files/mediabag/index.html#experimental-results",
    "href": "projects/project1/projects_files/mediabag/index.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyzed whether matched donations lead to an increased response rate of making a donation.\n\nimport matplotlib as plt\nfrom matplotlib import rcParams\n\nkarlan_df_copy = karlan_df.copy()\nkarlan_grouped = karlan_df.groupby([\"treatment\", \"control\"])[\"gave\"].mean()\nax = karlan_grouped.plot(kind='bar', color = [\"purple\", \"orange\"])\n\nrcParams['font.family'] = 'serif'  # Change 'serif' to the desired font family\nrcParams['font.serif'] = ['Avenir'] \nax.set_xlabel(\"Treatment and Control\")\nax.set_ylabel(\"Proportion of People who Donated\")\n\nax.set_title(\"Proportion of People who Donated in Treatment and Control\")\n\ngroup_labels = ['Treatment', 'Control']\nax.set_xticklabels(group_labels, rotation = 0)\n\nfor i, v in enumerate(karlan_grouped):\n    ax.text(i, v, f'{v:.4f}', ha='center', va='bottom')\n\n\n\n\n\n\n\n\nI also ran a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made, in addition to running a bivariate linear regression to demonstrate the same finding.\n\nfrom scipy.stats import ttest_ind\nimport scipy.stats as stats\nkarlan_treatment = karlan_df[karlan_df[\"treatment\"] == 1]\nkarlan_control = karlan_df[karlan_df[\"control\"] == 1]\nt_statistic, p_value = stats.ttest_ind(karlan_treatment[\"gave\"], karlan_control[\"gave\"])\n\nprint(\"T-statistic:\", t_statistic)\nprint(\"p-value:\", p_value)\n\n#Bivariate Linear regression on gave\nX = karlan_df[['treatment']]  # Features\ny = karlan_df['gave']  # Target variable\n\nmodel = LinearRegression()\nmodel.fit(X, y)\n\nprint('Coefficients:', model.coef_)\nprint('Intercept:', model.intercept_)\n\nT-statistic: 3.101361000543946\np-value: 0.0019274025949016988\nCoefficients: [0.00418035]\nIntercept: 0.017858212980165173\n\n\nThe output indicates a t-statistic of approximately 3.10 and a p-value of approximately 0.002.\nIn interpreting these results, it’s important to recall that the t-statistic measures the size of the difference between the treatment and control groups relative to the variability in the data. Thus, the larger the t-statistic, the more the means of the two groups differ. In this case, a t-statistic of 3.10 suggests a substantial difference between the means of the treatment and control groups.\nThe p-value, on the other hand, assesses the probability of observing such a large difference if there were no true difference between the treatment and control groups (i.e., if the null hypothesis were true). A small p-value (in this case, 0.002) indicates that the observed difference is unlikely to have occurred by random chance alone. Interpreted in the context of the experiment, these statistical results suggest that there is a statistically significant difference in charitable giving between the treatment and control groups. In other words, the intervention or treatment likely had an effect on the behavior of individuals in the treatment group compared to those in the control group.\nTherefore, this finding may imply that the certain interventions or nudges implemented in the treatment group, the matching and challenge grant letters, were effective in encouraging charitable giving behavior. Understanding the effectiveness of these interventions sheds light on the psychological mechanisms and motivations behind charitable giving, potentially informing future strategies for promoting philanthropy and altruism.\n\nProbit Regression\nNext I ran a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable was assesment to treatment or control.\n\n#Probit Regression\nimport statsmodels.api as sm\n\nX = karlan_df[['treatment', 'control']]\ny = karlan_df['gave']\n\nmodel = sm.Probit(y, X).fit()\n\nprint(model.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Wed, 17 Apr 2024   Pseudo R-squ.:               0.0009783\nTime:                        13:29:35   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\ntreatment     -2.0134      0.015   -131.734      0.000      -2.043      -1.983\ncontrol       -2.1001      0.023    -90.073      0.000      -2.146      -2.054\n==============================================================================\n\n\nProbit regression is a type of regression analysis used to model binary outcomes, similar to logistic regression. In probit regression, the relationship between the predictor variables and the binary outcome is modeled using the cumulative distribution function of the standard normal distribution (also known as the probit function). The model assumes that the linear combination of predictor variables is associated with the probability of the binary outcome.\n\n\n\nDifferences between Match Rates\nNext, I assessed the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\n\n# T-test for ratio2 (2:1 match) compared to 1:1 match\nt_stat_ratio2, p_value_ratio2 = ttest_ind(karlan_df[karlan_df['ratio2'] == 1]['gave'], karlan_df[karlan_df['ratio2'] == 0]['gave'])\n\n# T-test for ratio3 (3:1 match) compared to 1:1 match\nt_stat_ratio3, p_value_ratio3 = ttest_ind(karlan_df[karlan_df['ratio3'] == 1]['gave'], karlan_df[karlan_df['ratio3'] == 0]['gave'])\n\nprint(\"T-Test Results for 2:1 match ratio:\")\nprint(f\"T-Statistic: {t_stat_ratio2}, P-Value: {p_value_ratio2}\")\n\nprint(\"\\nT-Test Results for 3:1 match ratio:\")\nprint(f\"T-Statistic: {t_stat_ratio3}, P-Value: {p_value_ratio3}\")\n\nT-Test Results for 2:1 match ratio:\nT-Statistic: 1.6725548025261596, P-Value: 0.09442121711611902\n\nT-Test Results for 3:1 match ratio:\nT-Statistic: 1.7562202653799, P-Value: 0.07905691730335489\n\n\nOverall, based on these results, we do not have enough evidence to conclude that either the 2:1 match ratio or the 3:1 match ratio has a significantly different effect on charitable donations compared to the 1:1 match ratio. These findings match those of Karlan et al. They too found that “that neither the match threshold nor the example amount had a meaningful influence on behavior.”\n\nimport pyrsm as rsm\n\nreg_ratio = rsm.model.regress(\n    data = {\"Karlan DF\": karlan_df},\n    rvar = \"gave\",\n    evar = \"ratio\"\n)\n\nreg_ratio.summary()\n\nLinear regression (OLS)\nData                 : Karlan DF\nResponse variable    : gave\nExplanatory variables: ratio\nNull hyp.: the effect of x on gave is zero\nAlt. hyp.: the effect of x on gave is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.018      0.001   16.225  &lt; .001  ***\nratio[1]         0.003      0.002    1.661   0.097    .\nratio[2]         0.005      0.002    2.744   0.006   **\nratio[3]         0.005      0.002    2.802   0.005   **\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: 0.0\nF-statistic: 3.665 df(3, 50079), p.value 0.012\nNr obs: 50,083\n\n\nIn this regression, each ratio coefficient represents the effect of the corresponding ratio variable on charitable donations, holding other variables constant. Ratio[1]: The coefficient is positive (0.003), but it is not statistically significant at the 0.05 significance level (p = 0.097). Ratio[2]: The coefficient is positive (0.005) and statistically significant (p = 0.006), indicating that for each unit increase in ratio[2], charitable donations increase by 0.005 units, holding other variables constant. Ratio[3]: Similar to Ratio[2], the coefficient is positive (0.005) and statistically significant (p = 0.005), suggesting that for each unit increase in ratio[3], charitable donations increase by 0.005 units, holding other variables constant. The intercept represents the expected value of the dependent variable (charitable donations) when all explanatory variables (ratio) are zero. In this case, the intercept is statistically significant (p &lt; 0.001), indicating that when the ratio is zero, there is still a non-zero expected value of charitable donations.\nThe R-squared value (0.0) indicates that the model does not explain much of the variability in charitable donations. The F-statistic (3.665) tests the overall significance of the model. With a p-value of 0.012, the model is statistically significant, suggesting that at least one of the explanatory variables has a significant effect on charitable donations.\nOverall, the results suggest that ratio[2] and ratio[3] have a statistically significant positive effect on charitable donations, while ratio[1] does not have a statistically significant effect. However, it’s essential to consider the context of the study and potential limitations when interpreting these findings.\n\n# response rate difference between 1:1 and 2:1 match ratios\nrr_1_1 = len(karlan_df[(karlan_df['ratio'] == 1) & (karlan_df['gave'] == 1)]) / len(karlan_df[karlan_df['ratio'] == 1])\nrr_2_1 = len(karlan_df[(karlan_df['ratio'] == 2) & (karlan_df['gave'] == 1)]) / len(karlan_df[karlan_df['ratio'] == 2])\nrr_difference_1_2 = rr_2_1 - rr_1_1\n\n# response rate difference between 2:1 and 3:1 match ratios\nrr_3_1 = len(karlan_df[(karlan_df['ratio'] == 3) & (karlan_df['gave'] == 1)]) / len(karlan_df[karlan_df['ratio'] == 3])\nrr_difference_2_3 = rr_3_1 - rr_2_1\n\nprint(\"Response Rate Difference between 1:1 and 2:1 Match Ratios:\", rr_difference_1_2)\nprint(\"Response Rate Difference between 2:1 and 3:1 Match Ratios:\", rr_difference_2_3)\n\n\n### \n\ncoeff_ratio_1 = 0.003\ncoeff_ratio_2 = 0.005\ncoeff_ratio_3 = 0.005\n\n# response rate diff between 1:1 and 2:1 match ratios\nrr_diff_coef_1_2 = coeff_ratio_2 - coeff_ratio_1\n\n# response rate diff between 2:1 and 3:1 match ratios\nrr_diff_coef_2_3 = coeff_ratio_3 - coeff_ratio_2\n\nprint(\"Response Rate Difference (from Coefficients) between 1:1 and 2:1 Match Ratios:\", rr_diff_coef_1_2)\nprint(\"Response Rate Difference (from Coefficients) between 2:1 and 3:1 Match Ratios:\", rr_diff_coef_2_3)\n\nResponse Rate Difference between 1:1 and 2:1 Match Ratios: 0.0018842510217149944\nResponse Rate Difference between 2:1 and 3:1 Match Ratios: 0.00010002398025293902\nResponse Rate Difference (from Coefficients) between 1:1 and 2:1 Match Ratios: 0.002\nResponse Rate Difference (from Coefficients) between 2:1 and 3:1 Match Ratios: 0.0\n\n\nThe response rate difference between individuals in the 1:1 match ratio group and the 2:1 match ratio group is approximately 0.0019 (or 0.19%). The response rate difference (derived from the coefficients) between the 1:1 match ratio group and the 2:1 match ratio group is 0.002 (or 0.2%).\nThe response rate difference between individuals in the 2:1 match ratio group and the 3:1 match ratio group is approximately 0.0001 (or 0.01%), whereas the response rate difference (derived from the coefficients) between the 2:1 match ratio group and the 3:1 match ratio group is 0.0 (or no difference).\n1:1 vs. 2:1 Match Ratios: Both the direct data analysis and the coefficient analysis suggest that individuals in the 2:1 match ratio group have a slightly higher response rate compared to those in the 1:1 match ratio group. The difference is small but consistent across both analyses.\n2:1 vs. 3:1 Match Ratios: According to the direct data analysis, there is almost no difference in the response rates between the 2:1 match ratio group and the 3:1 match ratio group. However, the coefficient analysis indicates that the response rate difference between these groups is exactly zero.\nOverall, based on these findings, it seems that increasing the size of matched donations from 1:1 to 2:1 may lead to a slightly higher response rate, but further increasing the match ratio beyond 2:1 may not have a significant additional impact on the response rate.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyzed the effect of the size of matched donation on the size of the charitable contribution.\n\nfrom scipy.stats import ttest_ind\n\ntreatment_amount = karlan_df[karlan_df['treatment'] == 1]['amount']\ncontrol_amount = karlan_df[karlan_df['treatment'] == 0]['amount']\n\n# Perform the t-test\nt_statistic, p_value = ttest_ind(treatment_amount, control_amount)\n\n# Print the results\nprint(\"T-statistic:\", t_statistic)\nprint(\"P-value:\", p_value)\n\nT-statistic: 1.8605020225753781\nP-value: 0.06282038947470683\n\n\nT-test Approach: If the p-value from the t-test is less than a chosen significance level (e.g., 0.05), it indicates that there is a statistically significant difference in donation amounts between the treatment and control groups. This suggests that treatment status, such as the use of a matching grant letter or challenge grant letter, does have a statistically significant effect on donation amounts.\nBivariate Linear Regression Approach: If the coefficient for the ‘treatment’ variable in the linear regression model is statistically significant (p-value &lt; 0.05), it indicates that treatment status has a significant effect on donation amounts. The sign of the coefficient indicates the direction of the effect (positive or negative), and the magnitude represents the size of the effect.\nBoth the t-test approach and the Bivariate Linear Regression approach provide insights into the relationship between the treatment status and donation amounts. They help in understanding whether being in the treatment group influences the donation amounts compared to the control group.\n\ndonated_df = karlan_df[karlan_df['amount'] &gt; 0]\n\n#added a constant term for the intercept\ndonated_df['intercept'] = 1\nX = donated_df[['intercept', 'treatment']]\ny = donated_df['amount']\n\nmodel = sm.OLS(y, X).fit()\n\n\nprint(model.summary())\n###\n\ntreatment_amount = donated_df[donated_df['treatment'] == 1]['amount']\ncontrol_amount = donated_df[donated_df['treatment'] == 0]['amount']\n\nt_statistic, p_value = ttest_ind(treatment_amount, control_amount)\n\nprint(\"T-statistic:\", t_statistic)\nprint(\"P-value:\", p_value)\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.001\nMethod:                 Least Squares   F-statistic:                    0.3374\nDate:                Wed, 17 Apr 2024   Prob (F-statistic):              0.561\nTime:                        13:29:36   Log-Likelihood:                -5326.8\nNo. Observations:                1034   AIC:                         1.066e+04\nDf Residuals:                    1032   BIC:                         1.067e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept     45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\nOmnibus:                      587.258   Durbin-Watson:                   2.031\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5623.279\nSkew:                           2.464   Prob(JB):                         0.00\nKurtosis:                      13.307   Cond. No.                         3.49\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\nT-statistic: -0.5808388615237938\nP-value: 0.5614758782284279\n\n\n/var/folders/bj/t618x2614s9c896326lrdjw40000gn/T/ipykernel_7059/3304687072.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  donated_df['intercept'] = 1\n\n\nBased on these results, we can conclude that there is no significant difference in the amount donated by individuals in the treatment group compared to those in the control group. Therefore, the treatment coefficient does not have a causal interpretation regarding the effectiveness of the treatment on the amount donated. It suggests that the treatment (whatever it may be) does not significantly influence the donation amount.\n\nimport matplotlib.pyplot as plt\n\n#filtering the dataset for if a donation was made\ndonated_treatment = karlan_df[(karlan_df['amount'] &gt; 0) & (karlan_df['treatment'] == 1)]\ndonated_control = karlan_df[(karlan_df['amount'] &gt; 0) & (karlan_df['treatment'] == 0)]\n\n# sample averages for control and treatment\navg_treatment = donated_treatment['amount'].mean()\navg_control = donated_control['amount'].mean()\n\n# create histograms\nplt.figure(figsize=(10, 5))\n\n#histogram for treatment group\nplt.subplot(1, 2, 1)\nplt.hist(donated_treatment['amount'], color='blue', alpha=0.7)\nplt.axvline(avg_treatment, color='red', linestyle='dashed', linewidth=1, label='Sample Average')\nplt.xlabel('Donation Amount')\nplt.ylabel('Frequency')\nplt.title('Treatment Group')\nplt.legend()\n\n# histogram for control group\nplt.subplot(1, 2, 2)\nplt.hist(donated_control['amount'], color='green', alpha=0.7)\nplt.axvline(avg_control, color='red', linestyle='dashed', linewidth=1, label='Sample Average')\nplt.xlabel('Donation Amount')\nplt.ylabel('Frequency')\nplt.title('Control Group')\nplt.legend()\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Madeline Sands",
    "section": "Education",
    "text": "Education\nUniversity of California, San Diego | San Diego, CA Masters of Science in Business Analytics | July 2023 - December 2015\nUniversity of California, Irvine | Irvine, CA B.S in Analytical Chemistry | Sept 2015 - March 2020"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Madeline Sands",
    "section": "Experience",
    "text": "Experience"
  },
  {
    "objectID": "projects/project2/index.html",
    "href": "projects/project2/index.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved compared to traditional methods. Ideal data to study such an effect and prove some type of causal relationship might include the success rate of patent applications before using Blueprinty’s software and after using it if the use of Blueprinty was randomly assigned. Unfortunately, this data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data includes each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. Blueprinty’s marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\nimport pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \n\nblueprinty_df = pd.read_csv(\"data/blueprinty.csv\")\n\nblueprinty_df.info()\n\nprint(blueprinty_df.head())\n\ndummy_blueprinty_df = pd.get_dummies(blueprinty_df['region'], prefix='dummy_')\n\n# Concatenate the original DataFrame with the dummy variables DataFrame\nblueprinty = pd.concat([blueprinty_df, dummy_blueprinty_df], axis=1)\nprint(blueprinty.head())\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1500 entries, 0 to 1499\nData columns (total 5 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   Unnamed: 0  1500 non-null   int64  \n 1   patents     1500 non-null   int64  \n 2   region      1500 non-null   object \n 3   age         1500 non-null   float64\n 4   iscustomer  1500 non-null   int64  \ndtypes: float64(1), int64(3), object(1)\nmemory usage: 58.7+ KB\n   Unnamed: 0  patents     region   age  iscustomer\n0           1        0    Midwest  32.5           0\n1         786        3  Southwest  37.5           0\n2         348        4  Northwest  27.0           1\n3         927        3  Northeast  24.5           0\n4         830        3  Southwest  37.0           0\n   Unnamed: 0  patents     region   age  iscustomer  dummy__Midwest  \\\n0           1        0    Midwest  32.5           0            True   \n1         786        3  Southwest  37.5           0           False   \n2         348        4  Northwest  27.0           1           False   \n3         927        3  Northeast  24.5           0           False   \n4         830        3  Southwest  37.0           0           False   \n\n   dummy__Northeast  dummy__Northwest  dummy__South  dummy__Southwest  \n0             False             False         False             False  \n1             False             False         False              True  \n2             False              True         False             False  \n3              True             False         False             False  \n4             False             False         False              True  \n\n\n\ngrouped = blueprinty_df.groupby('iscustomer')['patents']\nmeans = grouped.mean()\n\n# Plot histograms for each group\nplt.figure(figsize=(10, 6))\nfor status, group_data in grouped:\n    plt.hist(group_data, alpha=0.5, label=status, bins=20)\n\n# Overlay mean lines\nfor status, mean in means.items():\n    plt.axvline(mean, color='k', linestyle='dashed', linewidth=1)\n    plt.text(mean + 0.1, 50, f'Group {status} Mean: {mean:.2f}', rotation=90)\n\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\nplt.title('Histogram of Number of Patents by Customer Status')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nThe histogram above shows the number of patents submitted by customer status as well as includes mean bars for the two groups. In this data set, 1 indicates that a engineering firm is a blueprinty customer and a 0 indicates that they are not a blueprinty customer. Based on this histogram, Blueprinty’s customers do have a slightly higher average number of patents submitted, 4.09 patents compared to the non-blueprinty customers, 3.62 patents. However, there are a couple of important caveats to these numbers. First, the non-blueprinty customer base not only is larger than that of blueprinty’s, but the range is wider, and especially hovers around the 0-2 patent range. This means that these customers could be bringing the average down among the non-blueprinty customer base. Additionally, Blueprinty customers are not selected at random. Therefore, additional systematic differences in the age and location of the engineering firms could be further contributing to the difference in the mean number of patents submitted.\nIt may be important to account for systematic differences in the age and regional location of customers vs non-customers. Therefore, we are going to examine the distribution of Blueprinty’s customers by regions and ages.\n\n\n\ngrouped = blueprinty_df.groupby('iscustomer')['region']\n\n# Plot histograms for each group\nplt.figure(figsize=(10, 6))\nfor status, group_data in grouped:\n    plt.hist(group_data, alpha=0.5, label=status, bins=10)\n\nplt.xlabel('Number of Customers')\nplt.ylabel('Frequency')\nplt.title('Histogram of Distribution of Blueprinty Customers by Region')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nBased on region, Blueprinty has the highest number of customers located in the Northeast. However, the Northeast also has the highest number of engineering firms out of all the other regions. If we were to take the average number of Blueprinty customer’s per region, blueprinty would have approximately 10% of the engineering firms among the various regions.\n\n\n\n\ngrouped_age = blueprinty_df.groupby('iscustomer')['age']\nmeans_age = grouped_age.mean()\n# Plot histograms for each group\nplt.figure(figsize=(10, 6))\nfor status, group_data in grouped_age:\n    plt.hist(group_data, alpha=0.5, label=status, bins=20)\n\nfor status, mean in means_age.items():\n    plt.axvline(mean, color='k', linestyle='dashed', linewidth=1)\n    plt.text(mean + 0.5, 75, f'{status} Mean: {mean:.2f} years', rotation=90)\n\nplt.xlabel('Age of Customers (years)')\nplt.ylabel('Frequency')\nplt.title('Histogram of Customer Age')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nThe histogram above shows the distribution of Blueprinty and non-Blueprinty customers by age. On average, Blueprinty’s customers are about 2.54 years younger than other customers. Additionally, there is a slight rightward skew to Blueprinty’s customers where they seem to have clients that have younger businesses, which would contribute to the younger average age of their client’s businesses. We can see that Blueprinty has been targeting younger buinesses compared to older businesses. This makes sense for Blueprinty, and could be part of their business plan. These businesses could have a greater ROI when using the Blueprinty software compared to an older business that has expertise submitting patents.\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we will use a Poisson density function to model the number of patents awarded to each engineering firm over the last 5 years. Just to note, a Poisson model is a distribution of discrete counts in a pre-determined time frame, hence why we will be using it instead of another distribution model.\nWe start by estimating a simple Poisson model via Maximum Likelihood.\nFirst, the likelihood function represents the probability of observing the data given a specific value of \\(\\lambda\\). To mathematically write down the likelihood for \\(Y \\sim \\text{Poisson}(\\lambda)\\), we first need to write down the density of the dependent variable for one observation. For a Poisson distribution, the density function is \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\nUsing this density function, we can then estimate the likelihood by multiplying the density together N times, where the n represents the number of observations.\nNext we want to take the natural log of the density and create the joint log-likelihood by adding the N log-densities together, which can be done due to log properties. Therefore, when we take the natural log of our liklihood function, we get \\(\\ln f(Y|\\lambda) = \\sum_{i=1}^{n} (-\\lambda + x_i \\ln(\\lambda) - \\ln(\\lambda))\\) .\nNext we want to maximize our likelihood function. To find the maximum likelihood estimate of λ, we need to maximize the logarithm of the likelihood function with respect to λ. This can be done by taking the derivative of the log-likelihood function with respect to λ, setting it equal to zero, and solving for λ: \\(\\frac{d \\ln L(\\lambda)}{d\\lambda} = 0\\)\nOnce we solve this function for λ, we have the parameter value that best fits the observed data according to the Poisson distribution.\n\nfrom scipy.special import factorial\n\ndef poisson_loglikelihood(lambda_value, Y):\n   log_likelihood = np.sum(-lambda_value + Y * np.log(lambda_value) - np.log(factorial(Y)))\n   return log_likelihood\n\nIn python, we can create a function that takes our lambda value and Y and returns our log likelihood value.\n\n# number of patents\nY = blueprinty_df[\"patents\"]\n\n#range of lambda values\nlambda_range = np.linspace(0.1, 20, 100)\n\n# log-likelihood for each lambda\nlog_likelihoods = [poisson_loglikelihood(lambda_val, Y) for lambda_val in lambda_range]\n\nplt.plot(lambda_range, log_likelihoods)\nplt.xlabel('Lambda')\nplt.ylabel('Log-Likelihood')\nplt.title('Log-Likelihood of Poisson Distribution')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nWhen we take the first derivative of our function and set it equal to 0, we are able to solve for the value that maximizes our function. This is because the first derivative indicates a rate or slope, and we are looking for the point of our function that has a 0 slope i.e. some type of peak. From the graphical representation above, we can see that our function has a max somewhere between 2.5 and 5 for our lambda value, or approximately 3.\n\nfrom scipy.optimize import fsolve\n\ndef poisson_loglikelihood_derivative(lambda_value, Y):\n    return np.sum(-1 + Y / lambda_value)\n\n# Observed number of patents\nY = blueprinty_df[\"patents\"] # Update with your observed value\n\n# Solve for lambda using fsolve\nlambda_mle = fsolve(poisson_loglikelihood_derivative, x0=1, args=(Y,))[0]\n\nprint(f\"Maximum Likelihood Estimate (MLE) for lambda: {lambda_mle:.3f}\")\n\nMaximum Likelihood Estimate (MLE) for lambda: 3.685\n\n\nWe don’t need to calculate our first derivative by hand each time, set equal to 0 and run. Instead, we can use the function scipy.optimize and fsolve to solved our function when it is set equal to 0 and find that value that maximizes our function. In this case, this MLE for lambda is 3.685.\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\ntodo: Update your likelihood or log-likelihood function with an additional argument to take in a covariate matrix X. Also change the parameter of the model from lambda to the beta vector. In this model, lambda must be a positive number, so we choose the inverse link function g() to be exp() so that \\(\\lambda_i = e^{X_i'\\beta}\\). For example:\n\ndef poisson_loglikelihood(beta, X, Y):\n   lambda_values = np.exp(np.dot(X, beta))\n   log_likelihood = np.sum(-lambda_values + Y * np.log(lambda_values) - np.log(factorial(Y)))\n   return log_likelihood\n\ntodo: Use your function along with R’s optim() or Python’s sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates. Specifically, the first column of X should be all 1’s to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable. Use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\n\nfrom scipy.optimize import minimize\ndef poisson_loglikelihood(beta, X, Y):\n   lambda_values = np.exp(np.dot(X, beta))\n   log_likelihood = np.sum(-lambda_values + Y * np.log(lambda_values) - np.log(factorial(Y)))\n# Define covariates matrix X \nX = blueprinty[['age', 'dummy__Midwest', 'dummy__Northeast', 'dummy__Northwest', 'dummy__South','dummy__Southwest', 'iscustomer']]\nX['constant'] = 1  # constant column\n\n# Create age squared column\nX['age_squared'] = X['age'] ** 2\n\n# Create binary variables for regions\nregions = blueprinty['region'].unique()\nfor region in regions[:-1]:\n    X[region] = (blueprinty['region'] == region).astype(int)\n\n# Drop one region to avoid multicollinearity, if it exists\nif regions[-1] in X.columns:\n    X.drop(columns=regions[-1], inplace=True)\n\n# Convert X and Y to numpy arrays\nX = X.values\nY = blueprinty['patents'].values\n\n# Initial guess for beta vector\ninitial_beta = np.zeros(X.shape[1])\n\n# Optimize the log-likelihood function using scipy.optimize\n#result = minimize(log_likelihood, initial_beta, args=(X, Y), method='BFGS')\n\n# MLE vector\n##mle_vector = result.x\n\n# Hessian of the Poisson model\n#hessian = result.hess_inv\n\n# Calculate standard errors of beta parameter estimates\n#se_beta = np.sqrt(np.diag(hessian))\n# Present a table of coefficients and standard errors\n#coefficients_table = pd.DataFrame({'Coefficients': mle_vector, 'Standard Errors': se_beta}, index=['constant', 'age', 'age_squared'] + list(regions[:-1]) + ['iscustomer'])\n#print(coefficients_table)\n\n/var/folders/bj/t618x2614s9c896326lrdjw40000gn/T/ipykernel_7182/3579629346.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  X['constant'] = 1  # constant column\n/var/folders/bj/t618x2614s9c896326lrdjw40000gn/T/ipykernel_7182/3579629346.py:10: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  X['age_squared'] = X['age'] ** 2\n\n\ntodo: Check your results using R’s glm() function or Python sm.GLM() function.\n\nimport statsmodels.api as sm\n#X = blueprinty[['age', 'dummy__Midwest', 'dummy__Northeast', 'dummy__Northwest', 'dummy__South','dummy__Southwest', 'iscustomer']]\n#Y = blueprinty['patents'].values\n#model = sm.GLM(Y, X, family=sm.families.Poisson()).fit()\n#print(model.summary())"
  },
  {
    "objectID": "projects/project2/index.html#blueprinty-case-study",
    "href": "projects/project2/index.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved compared to traditional methods. Ideal data to study such an effect and prove some type of causal relationship might include the success rate of patent applications before using Blueprinty’s software and after using it if the use of Blueprinty was randomly assigned. Unfortunately, this data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data includes each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. Blueprinty’s marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\nimport pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \n\nblueprinty_df = pd.read_csv(\"data/blueprinty.csv\")\n\nblueprinty_df.info()\n\nprint(blueprinty_df.head())\n\ndummy_blueprinty_df = pd.get_dummies(blueprinty_df['region'], prefix='dummy_')\n\n# Concatenate the original DataFrame with the dummy variables DataFrame\nblueprinty = pd.concat([blueprinty_df, dummy_blueprinty_df], axis=1)\nprint(blueprinty.head())\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1500 entries, 0 to 1499\nData columns (total 5 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   Unnamed: 0  1500 non-null   int64  \n 1   patents     1500 non-null   int64  \n 2   region      1500 non-null   object \n 3   age         1500 non-null   float64\n 4   iscustomer  1500 non-null   int64  \ndtypes: float64(1), int64(3), object(1)\nmemory usage: 58.7+ KB\n   Unnamed: 0  patents     region   age  iscustomer\n0           1        0    Midwest  32.5           0\n1         786        3  Southwest  37.5           0\n2         348        4  Northwest  27.0           1\n3         927        3  Northeast  24.5           0\n4         830        3  Southwest  37.0           0\n   Unnamed: 0  patents     region   age  iscustomer  dummy__Midwest  \\\n0           1        0    Midwest  32.5           0            True   \n1         786        3  Southwest  37.5           0           False   \n2         348        4  Northwest  27.0           1           False   \n3         927        3  Northeast  24.5           0           False   \n4         830        3  Southwest  37.0           0           False   \n\n   dummy__Northeast  dummy__Northwest  dummy__South  dummy__Southwest  \n0             False             False         False             False  \n1             False             False         False              True  \n2             False              True         False             False  \n3              True             False         False             False  \n4             False             False         False              True  \n\n\n\ngrouped = blueprinty_df.groupby('iscustomer')['patents']\nmeans = grouped.mean()\n\n# Plot histograms for each group\nplt.figure(figsize=(10, 6))\nfor status, group_data in grouped:\n    plt.hist(group_data, alpha=0.5, label=status, bins=20)\n\n# Overlay mean lines\nfor status, mean in means.items():\n    plt.axvline(mean, color='k', linestyle='dashed', linewidth=1)\n    plt.text(mean + 0.1, 50, f'Group {status} Mean: {mean:.2f}', rotation=90)\n\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\nplt.title('Histogram of Number of Patents by Customer Status')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nThe histogram above shows the number of patents submitted by customer status as well as includes mean bars for the two groups. In this data set, 1 indicates that a engineering firm is a blueprinty customer and a 0 indicates that they are not a blueprinty customer. Based on this histogram, Blueprinty’s customers do have a slightly higher average number of patents submitted, 4.09 patents compared to the non-blueprinty customers, 3.62 patents. However, there are a couple of important caveats to these numbers. First, the non-blueprinty customer base not only is larger than that of blueprinty’s, but the range is wider, and especially hovers around the 0-2 patent range. This means that these customers could be bringing the average down among the non-blueprinty customer base. Additionally, Blueprinty customers are not selected at random. Therefore, additional systematic differences in the age and location of the engineering firms could be further contributing to the difference in the mean number of patents submitted.\nIt may be important to account for systematic differences in the age and regional location of customers vs non-customers. Therefore, we are going to examine the distribution of Blueprinty’s customers by regions and ages.\n\n\n\ngrouped = blueprinty_df.groupby('iscustomer')['region']\n\n# Plot histograms for each group\nplt.figure(figsize=(10, 6))\nfor status, group_data in grouped:\n    plt.hist(group_data, alpha=0.5, label=status, bins=10)\n\nplt.xlabel('Number of Customers')\nplt.ylabel('Frequency')\nplt.title('Histogram of Distribution of Blueprinty Customers by Region')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nBased on region, Blueprinty has the highest number of customers located in the Northeast. However, the Northeast also has the highest number of engineering firms out of all the other regions. If we were to take the average number of Blueprinty customer’s per region, blueprinty would have approximately 10% of the engineering firms among the various regions.\n\n\n\n\ngrouped_age = blueprinty_df.groupby('iscustomer')['age']\nmeans_age = grouped_age.mean()\n# Plot histograms for each group\nplt.figure(figsize=(10, 6))\nfor status, group_data in grouped_age:\n    plt.hist(group_data, alpha=0.5, label=status, bins=20)\n\nfor status, mean in means_age.items():\n    plt.axvline(mean, color='k', linestyle='dashed', linewidth=1)\n    plt.text(mean + 0.5, 75, f'{status} Mean: {mean:.2f} years', rotation=90)\n\nplt.xlabel('Age of Customers (years)')\nplt.ylabel('Frequency')\nplt.title('Histogram of Customer Age')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nThe histogram above shows the distribution of Blueprinty and non-Blueprinty customers by age. On average, Blueprinty’s customers are about 2.54 years younger than other customers. Additionally, there is a slight rightward skew to Blueprinty’s customers where they seem to have clients that have younger businesses, which would contribute to the younger average age of their client’s businesses. We can see that Blueprinty has been targeting younger buinesses compared to older businesses. This makes sense for Blueprinty, and could be part of their business plan. These businesses could have a greater ROI when using the Blueprinty software compared to an older business that has expertise submitting patents.\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we will use a Poisson density function to model the number of patents awarded to each engineering firm over the last 5 years. Just to note, a Poisson model is a distribution of discrete counts in a pre-determined time frame, hence why we will be using it instead of another distribution model.\nWe start by estimating a simple Poisson model via Maximum Likelihood.\nFirst, the likelihood function represents the probability of observing the data given a specific value of \\(\\lambda\\). To mathematically write down the likelihood for \\(Y \\sim \\text{Poisson}(\\lambda)\\), we first need to write down the density of the dependent variable for one observation. For a Poisson distribution, the density function is \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\nUsing this density function, we can then estimate the likelihood by multiplying the density together N times, where the n represents the number of observations.\nNext we want to take the natural log of the density and create the joint log-likelihood by adding the N log-densities together, which can be done due to log properties. Therefore, when we take the natural log of our liklihood function, we get \\(\\ln f(Y|\\lambda) = \\sum_{i=1}^{n} (-\\lambda + x_i \\ln(\\lambda) - \\ln(\\lambda))\\) .\nNext we want to maximize our likelihood function. To find the maximum likelihood estimate of λ, we need to maximize the logarithm of the likelihood function with respect to λ. This can be done by taking the derivative of the log-likelihood function with respect to λ, setting it equal to zero, and solving for λ: \\(\\frac{d \\ln L(\\lambda)}{d\\lambda} = 0\\)\nOnce we solve this function for λ, we have the parameter value that best fits the observed data according to the Poisson distribution.\n\nfrom scipy.special import factorial\n\ndef poisson_loglikelihood(lambda_value, Y):\n   log_likelihood = np.sum(-lambda_value + Y * np.log(lambda_value) - np.log(factorial(Y)))\n   return log_likelihood\n\nIn python, we can create a function that takes our lambda value and Y and returns our log likelihood value.\n\n# number of patents\nY = blueprinty_df[\"patents\"]\n\n#range of lambda values\nlambda_range = np.linspace(0.1, 20, 100)\n\n# log-likelihood for each lambda\nlog_likelihoods = [poisson_loglikelihood(lambda_val, Y) for lambda_val in lambda_range]\n\nplt.plot(lambda_range, log_likelihoods)\nplt.xlabel('Lambda')\nplt.ylabel('Log-Likelihood')\nplt.title('Log-Likelihood of Poisson Distribution')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nWhen we take the first derivative of our function and set it equal to 0, we are able to solve for the value that maximizes our function. This is because the first derivative indicates a rate or slope, and we are looking for the point of our function that has a 0 slope i.e. some type of peak. From the graphical representation above, we can see that our function has a max somewhere between 2.5 and 5 for our lambda value, or approximately 3.\n\nfrom scipy.optimize import fsolve\n\ndef poisson_loglikelihood_derivative(lambda_value, Y):\n    return np.sum(-1 + Y / lambda_value)\n\n# Observed number of patents\nY = blueprinty_df[\"patents\"] # Update with your observed value\n\n# Solve for lambda using fsolve\nlambda_mle = fsolve(poisson_loglikelihood_derivative, x0=1, args=(Y,))[0]\n\nprint(f\"Maximum Likelihood Estimate (MLE) for lambda: {lambda_mle:.3f}\")\n\nMaximum Likelihood Estimate (MLE) for lambda: 3.685\n\n\nWe don’t need to calculate our first derivative by hand each time, set equal to 0 and run. Instead, we can use the function scipy.optimize and fsolve to solved our function when it is set equal to 0 and find that value that maximizes our function. In this case, this MLE for lambda is 3.685.\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\ntodo: Update your likelihood or log-likelihood function with an additional argument to take in a covariate matrix X. Also change the parameter of the model from lambda to the beta vector. In this model, lambda must be a positive number, so we choose the inverse link function g() to be exp() so that \\(\\lambda_i = e^{X_i'\\beta}\\). For example:\n\ndef poisson_loglikelihood(beta, X, Y):\n   lambda_values = np.exp(np.dot(X, beta))\n   log_likelihood = np.sum(-lambda_values + Y * np.log(lambda_values) - np.log(factorial(Y)))\n   return log_likelihood\n\ntodo: Use your function along with R’s optim() or Python’s sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates. Specifically, the first column of X should be all 1’s to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable. Use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\n\nfrom scipy.optimize import minimize\ndef poisson_loglikelihood(beta, X, Y):\n   lambda_values = np.exp(np.dot(X, beta))\n   log_likelihood = np.sum(-lambda_values + Y * np.log(lambda_values) - np.log(factorial(Y)))\n# Define covariates matrix X \nX = blueprinty[['age', 'dummy__Midwest', 'dummy__Northeast', 'dummy__Northwest', 'dummy__South','dummy__Southwest', 'iscustomer']]\nX['constant'] = 1  # constant column\n\n# Create age squared column\nX['age_squared'] = X['age'] ** 2\n\n# Create binary variables for regions\nregions = blueprinty['region'].unique()\nfor region in regions[:-1]:\n    X[region] = (blueprinty['region'] == region).astype(int)\n\n# Drop one region to avoid multicollinearity, if it exists\nif regions[-1] in X.columns:\n    X.drop(columns=regions[-1], inplace=True)\n\n# Convert X and Y to numpy arrays\nX = X.values\nY = blueprinty['patents'].values\n\n# Initial guess for beta vector\ninitial_beta = np.zeros(X.shape[1])\n\n# Optimize the log-likelihood function using scipy.optimize\n#result = minimize(log_likelihood, initial_beta, args=(X, Y), method='BFGS')\n\n# MLE vector\n##mle_vector = result.x\n\n# Hessian of the Poisson model\n#hessian = result.hess_inv\n\n# Calculate standard errors of beta parameter estimates\n#se_beta = np.sqrt(np.diag(hessian))\n# Present a table of coefficients and standard errors\n#coefficients_table = pd.DataFrame({'Coefficients': mle_vector, 'Standard Errors': se_beta}, index=['constant', 'age', 'age_squared'] + list(regions[:-1]) + ['iscustomer'])\n#print(coefficients_table)\n\n/var/folders/bj/t618x2614s9c896326lrdjw40000gn/T/ipykernel_7182/3579629346.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  X['constant'] = 1  # constant column\n/var/folders/bj/t618x2614s9c896326lrdjw40000gn/T/ipykernel_7182/3579629346.py:10: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  X['age_squared'] = X['age'] ** 2\n\n\ntodo: Check your results using R’s glm() function or Python sm.GLM() function.\n\nimport statsmodels.api as sm\n#X = blueprinty[['age', 'dummy__Midwest', 'dummy__Northeast', 'dummy__Northwest', 'dummy__South','dummy__Southwest', 'iscustomer']]\n#Y = blueprinty['patents'].values\n#model = sm.GLM(Y, X, family=sm.families.Poisson()).fit()\n#print(model.summary())"
  },
  {
    "objectID": "projects/project2/index.html#airbnb-case-study",
    "href": "projects/project2/index.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\ntodo: Assume the number of reviews is a good proxy for the number of bookings. Perform some exploratory data analysis to get a feel for the data, handle or drop observations with missing values on relevant variables, build one or more models (e.g., a poisson regression model for the number of bookings as proxied by the number of reviews), and interpret model coefficients to describe variation in the number of reviews as a function of the variables provided."
  },
  {
    "objectID": "projects/project2/index.html#introduction-2",
    "href": "projects/project2/index.html#introduction-2",
    "title": "Poisson Regression Examples",
    "section": "Introduction",
    "text": "Introduction\nHere, we have been provided with 40,000 Airbnb listings from New York City. We are assuming that the number os reviews are a good proxy for the number of bookings on the Airbnb platform. Our goal is going to attempt to find the number of bookings an airbnb listing has via a function of the number of reviews the airbnb listing has received.\n\nData\n\nimport pandas as pd \nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\n\nairbnb = pd.read_csv(\"data/airbnb.csv\")\nairbnb.head()\n\nprint(airbnb.isnull().sum())\nairbnb = airbnb[[\"id\", \"days\", \"last_scraped\", \"host_since\", \"room_type\", \"bathrooms\", \"bedrooms\", \"price\", \"number_of_reviews\", \"review_scores_cleanliness\", \"review_scores_location\", \"review_scores_value\", \"instant_bookable\"]]\n\nairbnb.info()\n\nairbnb.dropna(inplace = True)\n\nUnnamed: 0                       0\nid                               0\ndays                             0\nlast_scraped                     0\nhost_since                      35\nroom_type                        0\nbathrooms                      160\nbedrooms                        76\nprice                            0\nnumber_of_reviews                0\nreview_scores_cleanliness    10195\nreview_scores_location       10254\nreview_scores_value          10256\ninstant_bookable                 0\ndtype: int64\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 40628 entries, 0 to 40627\nData columns (total 13 columns):\n #   Column                     Non-Null Count  Dtype  \n---  ------                     --------------  -----  \n 0   id                         40628 non-null  int64  \n 1   days                       40628 non-null  int64  \n 2   last_scraped               40628 non-null  object \n 3   host_since                 40593 non-null  object \n 4   room_type                  40628 non-null  object \n 5   bathrooms                  40468 non-null  float64\n 6   bedrooms                   40552 non-null  float64\n 7   price                      40628 non-null  int64  \n 8   number_of_reviews          40628 non-null  int64  \n 9   review_scores_cleanliness  30433 non-null  float64\n 10  review_scores_location     30374 non-null  float64\n 11  review_scores_value        30372 non-null  float64\n 12  instant_bookable           40628 non-null  object \ndtypes: float64(5), int64(4), object(4)\nmemory usage: 4.0+ MB\n\n\nWe will first conduct some exploratory data analysis to get a feel for the data. From airbnb.info() we see that we have 13 variables in our dataframe with the max number of rows being 40628. There do be some missing values, such as in bedrooms, host_since, review_scores_cleanliness, review_scores_location, and review_scores_value.\nFirst, we want to examine the distribution of room_type by the number of reviews number_of_reviews.\n\nairbnb_room = airbnb[['room_type']]\nplt.hist(airbnb_room, bins=20, alpha = 0.5)\nplt.xlabel('Airbnb Room Type and Number of Reviews')\nplt.ylabel('Frequency')\nplt.title('Histogram of Room Type and Number of reviews')\nplt.show()\n\n\n\n\n\n\n\n\nAs we can see, Airbnb tends to have either private rooms and entire homes or apts. There is not much information on shared rooms on the Airbnb platform.\n\nairbnb_price = airbnb[['price']]\nx_range = (0, 2200)\nplt.hist(airbnb_price, range =x_range, bins=100, alpha = 0.5)\n\nplt.xlabel('Price of Airbnb Listing')\nplt.ylabel('Frequency')\nplt.title('Histogram of Price')\nplt.show()\n\n\n\n\n\n\n\n\nThe price of airbnb listing’s range from close to 0 all the way up to 2000 per night. The most common price seems to be around $100/night. Additionally, because we are missing some variables from the price column, we want to potentially fill in the missing information to run a logistic regression from this data.\n\nsns.pairplot(airbnb[['bathrooms', 'bedrooms', 'price', 'number_of_reviews']])\nplt.show()\n\n\n\n\n\n\n\n\n\nimport pyrsm as rsm\n\nmapping = {\"t\": 1, \"f\": 0}\nairbnb[\"instant_bookable\"] = airbnb[\"instant_bookable\"].map(mapping)\n\n# want to build a Poisson regression model\nX = airbnb[['bathrooms', 'bedrooms', 'price', \"review_scores_cleanliness\", \"instant_bookable\", \"review_scores_value\", \"review_scores_location\"]]\ny = airbnb['number_of_reviews']\n\n# Add constant for intercept\nX = sm.add_constant(X)\n\n# Fit Poisson regression model\nmodel = sm.GLM(y, X, family=sm.families.Poisson()).fit()\n\n# Print model summary\nprint(model.summary())\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:      number_of_reviews   No. Observations:                30140\nModel:                            GLM   Df Residuals:                    30132\nModel Family:                 Poisson   Df Model:                            7\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:            -5.2905e+05\nDate:                Wed, 01 May 2024   Deviance:                   9.3672e+05\nTime:                        22:05:57   Pearson chi2:                 1.41e+06\nNo. Iterations:                     6   Pseudo R-squ. (CS):             0.5518\nCovariance Type:            nonrobust                                         \n=============================================================================================\n                                coef    std err          z      P&gt;|z|      [0.025      0.975]\n---------------------------------------------------------------------------------------------\nconst                         3.5414      0.016    224.237      0.000       3.510       3.572\nbathrooms                    -0.1286      0.004    -34.537      0.000      -0.136      -0.121\nbedrooms                      0.0785      0.002     39.944      0.000       0.075       0.082\nprice                      1.059e-05   7.43e-06      1.425      0.154   -3.97e-06    2.51e-05\nreview_scores_cleanliness     0.1136      0.001     76.229      0.000       0.111       0.117\ninstant_bookable              0.3321      0.003    115.247      0.000       0.326       0.338\nreview_scores_value          -0.0916      0.002    -51.094      0.000      -0.095      -0.088\nreview_scores_location       -0.0754      0.002    -47.098      0.000      -0.079      -0.072\n=============================================================================================\n\n\nThe output provided is from a Poisson regression model that aims to predict the number of reviews as a proxy for the number of bookings based on various predictor variables. Here’s how we can interpret the model coefficients in the context of the given statement:\n\n\nIntercept (const): The intercept term represents the expected number of reviews when all predictor variables are zero. In this model, the intercept is 3.5414. This means that when all other predictor variables are zero, we would expect approximately 34.41 reviews.\n\n\nbathrooms: The coefficient for the bathrooms variable is -0.1286. This suggests that for each additional bathroom, we would expect the number of reviews to decrease by approximately 0.1286, holding other variables constant. This might imply that listings with more bathrooms tend to receive fewer reviews, possibly due to higher pricing or reduced occupancy.\n\n\nbedrooms: The coefficient for the bedrooms variable is 0.0785. This indicates that for each additional bedroom, we would expect the number of reviews to increase by approximately 0.0785, holding other variables constant. This suggests that listings with more bedrooms tend to receive more reviews, possibly because they accommodate larger groups or families.\n\n\nprice: The coefficient for the price variable is 1.059e-05, but its p-value is 0.154, which is greater than the typical significance level of 0.05. This suggests that the effect of price on the number of reviews is not statistically significant at the 95% confidence level. In other words, changes in price do not have a significant impact on the number of reviews in this model.\n\n\nreview_scores_cleanliness: The coefficient for the review_scores_cleanliness variable is 0.1136. This suggests that for each unit increase in cleanliness score, we would expect the number of reviews to increase by approximately 0.1136, holding other variables constant. This implies that listings with higher cleanliness scores tend to receive more reviews.\n\n\ninstant_bookable: The coefficient for the instant_bookable variable is 0.3321. This indicates that listings that are instantly bookable tend to receive more reviews compared to those that are not, with an increase of approximately 0.3321 in the expected number of reviews.\n\n\nreview_scores_value: The coefficient for the review_scores_value variable is -0.0916. This suggests that for each unit increase in value score, we would expect the number of reviews to decrease by approximately 0.0916, holding other variables constant. This might indicate that listings perceived as offering better value tend to receive fewer reviews.\n\n\nreview_scores_location: The coefficient for the review_scores_location variable is -0.0754. This indicates that for each unit increase in location score, we would expect the number of reviews to decrease by approximately 0.0754, holding other variables constant. This could imply that listings in better locations receive fewer reviews, possibly because they are more expensive or have fewer available dates due to high demand.\n\n\nOverall, this model suggests that various factors such as the number of bathrooms, bedrooms, cleanliness scores, instant bookability, and value perception significantly influence the number of reviews received, while the effect of price and location scores is not statistically significant at the chosen significance level."
  },
  {
    "objectID": "projects/project2/Interactive-1.html",
    "href": "projects/project2/Interactive-1.html",
    "title": "Madeline Sands",
    "section": "",
    "text": "Connected to Python 3.11.6\n\nblueprinty_df = pd.read_csv(\"data/blueprinty.csv\")\n\nNameError: name 'pd' is not defined\n\n\n\nimport pandas as pd \nimport numpy as np \n\nblueprinty_df = pd.read_csv(\"data/blueprinty.csv\")\n\n\nimport pandas as pd \nimport numpy as np \n\nblueprinty_df = pd.read_csv(\"data/blueprinty.csv\")\n\nprint(blueprinty_df.head())\n\n   Unnamed: 0  patents     region   age  iscustomer\n0           1        0    Midwest  32.5           0\n1         786        3  Southwest  37.5           0\n2         348        4  Northwest  27.0           1\n3         927        3  Northeast  24.5           0\n4         830        3  Southwest  37.0           0\n\n\n\nimport pandas as pd \nimport numpy as np \nimport matplotlib as plt \n\nblueprinty_df = pd.read_csv(\"data/blueprinty.csv\")\n\nprint(blueprinty_df.head())\n\n   Unnamed: 0  patents     region   age  iscustomer\n0           1        0    Midwest  32.5           0\n1         786        3  Southwest  37.5           0\n2         348        4  Northwest  27.0           1\n3         927        3  Northeast  24.5           0\n4         830        3  Southwest  37.0           0\n\n\n\nblueprinty_df.hist(figsize=(20,20))\n\narray([[&lt;Axes: title={'center': 'Unnamed: 0'}&gt;,\n        &lt;Axes: title={'center': 'patents'}&gt;],\n       [&lt;Axes: title={'center': 'age'}&gt;,\n        &lt;Axes: title={'center': 'iscustomer'}&gt;]], dtype=object)\n\n\n\n\n\n\n\n\n\n\ngrouped = blueprinty_df.groupby('iscustomer')['patents']\nmeans = grouped.mean()\n\n# Plot histograms for each group\nplt.figure(figsize=(10, 6))\nfor status, group_data in grouped:\n    plt.hist(group_data, alpha=0.5, label=status, bins=20)\n\n# Overlay mean lines\nfor status, mean in means.items():\n    plt.axvline(mean, color='k', linestyle='dashed', linewidth=1)\n    plt.text(mean + 0.1, 50, f'Mean: {mean:.2f}', rotation=90)\n\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\nplt.title('Histogram of Number of Patents by Customer Status')\nplt.legend()\nplt.grid(True)\nplt.show()\n\nTypeError: 'module' object is not callable\n\n\n\ngrouped = blueprinty_df.groupby('iscustomer')['patents']\nmeans = grouped.mean()\n\n# Plot histograms for each group\n\nfor status, group_data in grouped:\n    plt.hist(group_data, alpha=0.5, label=status, bins=20)\n\n# Overlay mean lines\nfor status, mean in means.items():\n    plt.axvline(mean, color='k', linestyle='dashed', linewidth=1)\n    plt.text(mean + 0.1, 50, f'Mean: {mean:.2f}', rotation=90)\n\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\nplt.title('Histogram of Number of Patents by Customer Status')\nplt.legend()\nplt.grid(True)\nplt.show()\n\nAttributeError: module 'matplotlib' has no attribute 'hist'\n\n\n\nimport pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \n\nblueprinty_df = pd.read_csv(\"data/blueprinty.csv\")\n\nprint(blueprinty_df.head())\n\n   Unnamed: 0  patents     region   age  iscustomer\n0           1        0    Midwest  32.5           0\n1         786        3  Southwest  37.5           0\n2         348        4  Northwest  27.0           1\n3         927        3  Northeast  24.5           0\n4         830        3  Southwest  37.0           0\n\n\n\ngrouped = blueprinty_df.groupby('iscustomer')['patents']\nmeans = grouped.mean()\n\n# Plot histograms for each group\nplt.figure(figsize=(10, 6))\nfor status, group_data in grouped:\n    plt.hist(group_data, alpha=0.5, label=status, bins=20)\n\n# Overlay mean lines\nfor status, mean in means.items():\n    plt.axvline(mean, color='k', linestyle='dashed', linewidth=1)\n    plt.text(mean + 0.1, 50, f'Mean: {mean:.2f}', rotation=90)\n\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\nplt.title('Histogram of Number of Patents by Customer Status')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\ngrouped = blueprinty_df.groupby('iscustomer')['patents']\nmeans = grouped.mean()\n\n# Plot histograms for each group\nplt.figure(figsize=(10, 6))\nfor status, group_data in grouped:\n    plt.hist(group_data, alpha=0.5, label=status, bins=20)\n\n# Overlay mean lines\nfor status, mean in means.items():\n    plt.axvline(mean, color='k', linestyle='dashed', linewidth=1)\n    plt.text(mean + 0.1, 50, f'{status} Mean: {mean:.2f}', rotation=90)\n\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\nplt.title('Histogram of Number of Patents by Customer Status')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\ngrouped = blueprinty_df.groupby('iscustomer')['patents']\nmeans = grouped.mean()\n\n# Plot histograms for each group\nplt.figure(figsize=(10, 6))\nfor status, group_data in grouped:\n    plt.hist(group_data, alpha=0.5, label=status, bins=20)\n\n# Overlay mean lines\nfor status, mean in means.items():\n    plt.axvline(mean, color='k', linestyle='dashed', linewidth=1)\n    plt.text(mean + 0.1, 50, f'Group {status} Mean: {mean:.2f}', rotation=90)\n\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\nplt.title('Histogram of Number of Patents by Customer Status')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\ngrouped = blueprinty_df.groupby('iscustomer')['region']\n\n# Plot histograms for each group\nplt.figure(figsize=(10, 6))\nfor status, group_data in grouped:\n    plt.hist(group_data, alpha=0.5, label=status, bins=20)\n\n\nplt.xlabel('Number of Customers')\nplt.ylabel('Frequency')\nplt.title('Histogram of Number of Patents by Customer Status')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom scipy.special import factorial\n\ndef poisson_loglikelihood(lambda, Y):\n   log_likelihood = np.sum(-lambda + Y * np.log(lambda) - np.log(factorial(Y)))\n    return log_likelihood\n\nSyntaxError: invalid syntax (&lt;ipython-input-13-ae46d2fd1004&gt;, line 3)\n\n\n\nfrom scipy.special import factorial\n\ndef poisson_loglikelihood(lambda, Y):\n   log_likelihood = np.sum(-lambda + Y * np.log(lambda) - np.log(factorial(Y))\n   return log_likelihood\n\nSyntaxError: invalid syntax (&lt;ipython-input-14-fcc0dbaf773f&gt;, line 3)\n\n\n\nfrom scipy.special import factorial\n\ndef poisson_loglikelihood(lambda, Y):\n   log_likelihood = np.sum(-lambda + Y * np.log(lambda) - np.log(factorial(Y)))\n   return log_likelihood\n\nSyntaxError: invalid syntax (&lt;ipython-input-15-18d9d4e4a582&gt;, line 3)\n\n\n\nfrom scipy.special import factorial\n\ndef poisson_loglikelihood(lambda_value, Y):\n   log_likelihood = np.sum(-lambda_value + Y * np.log(lambda_value) - np.log(factorial(Y)))\n   return log_likelihood\n\n\n# Observed number of patents\nY = blueprinty_df[\"patents\"]  # Update with your observed value\n\n# Define a range of lambda values\nlambda_range = np.linspace(0.1, 20, 100)  # Adjust the range as needed\n\n# Calculate log-likelihood for each lambda\nlog_likelihoods = [poisson_loglikelihood(lambda_val, Y) for lambda_val in lambda_range]\n\n# Plot lambda values against log-likelihood\nplt.plot(lambda_range, log_likelihoods)\nplt.xlabel('Lambda')\nplt.ylabel('Log-Likelihood')\nplt.title('Log-Likelihood of Poisson Distribution')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom scipy.optimize import fsolve\n\ndef poisson_loglikelihood_derivative(lambda_value, Y):\n    return np.sum(-1 + Y / lambda_value)\n\n# Observed number of patents\nY = blueprinty_df[\"patents\"] # Update with your observed value\n\n# Solve for lambda using fsolve\nlambda_mle = fsolve(poisson_loglikelihood_derivative, x0=1, args=(Y,))[0]\n\nprint(\"Maximum Likelihood Estimate (MLE) for lambda:\", lambda_mle)\n\nMaximum Likelihood Estimate (MLE) for lambda: 3.6846666666666663"
  }
]