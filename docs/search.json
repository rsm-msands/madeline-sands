[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Madeline Sands",
    "section": "",
    "text": "Welcome to my website!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Madeline Sands",
    "section": "",
    "text": "Madeline is the Senior Category Data Manager at Scientist.com and Data Scientist. When not learning about machine learning and natural language processing, she enjoys spending time road and mountain biking, throwing pottery, and being outside."
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "My Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "projects/project1/projects_files/mediabag/index.html",
    "href": "projects/project1/projects_files/mediabag/index.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe goal of their project was to test the effectiveness of a matching grant on chartiable giving. Via their large-scale natural field experiment, they found that providing a match offer increases both the charitable revenue per solicitation and the response rate to the letters. However, the larger amount of the match ratio, (i.e. $3:$1 and $2:$1), relative to a smaller match ratio, ($1:$1), had no additional impact on the revenue per solicitation nor the response rate to the letter.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\n\n\nMadeline Sands\n\n\nApr 16, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/project1/projects_files/mediabag/index.html#introduction",
    "href": "projects/project1/projects_files/mediabag/index.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe goal of their project was to test the effectiveness of a matching grant on chartiable giving. Via their large-scale natural field experiment, they found that providing a match offer increases both the charitable revenue per solicitation and the response rate to the letters. However, the larger amount of the match ratio, (i.e. $3:$1 and $2:$1), relative to a smaller match ratio, ($1:$1), had no additional impact on the revenue per solicitation nor the response rate to the letter.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/project1/projects_files/mediabag/index.html#data",
    "href": "projects/project1/projects_files/mediabag/index.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nimport numpy as np \nimport pandas as pd \nfrom scipy.stats import t\nfrom scipy.stats import ttest_ind\n\nkarlan_df = pd.read_stata('data/karlan_list_2007.dta')\n\n\nDescription\nBelow is a general overview of the data from Karlan et. al 2007. A sample of approximately 50,000 individuals who had given to a charitable organization since 1991 were randomized and assigned into either a “match” treatment group or a control group. The treatment group was offered a matching grant conditional on their donation, with the goal to see if the match rate increases the likelihood of a donation in a charitable setting. This dataset contains information such as if the participant was part of the treatment or control, the match ratio, and the size of the donation, in addition to further characteristics about the donor and the donation they made.\n\nkarlan_df.describe()\n\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio2\nratio3\nsize25\nsize50\nsize100\nsizeno\naskd1\naskd2\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\ncount\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n...\n49978.000000\n49978.000000\n48217.000000\n48047.000000\n48217.000000\n48221.000000\n48209.000000\n48214.000000\n48215.000000\n48217.000000\n\n\nmean\n0.666813\n0.333187\n0.222311\n0.222211\n0.166723\n0.166623\n0.166723\n0.166743\n0.222311\n0.222291\n...\n0.510245\n0.488715\n0.819599\n0.086710\n0.321694\n2.429012\n54815.700533\n0.669418\n0.391661\n0.871968\n\n\nstd\n0.471357\n0.471357\n0.415803\n0.415736\n0.372732\n0.372643\n0.372732\n0.372750\n0.415803\n0.415790\n...\n0.499900\n0.499878\n0.168561\n0.135868\n0.103039\n0.378115\n22027.316665\n0.193405\n0.186599\n0.258654\n\n\nmin\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.009418\n0.000000\n0.000000\n0.000000\n5000.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.755845\n0.014729\n0.258311\n2.210000\n39181.000000\n0.560222\n0.235647\n0.884929\n\n\n50%\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n0.000000\n0.872797\n0.036554\n0.305534\n2.440000\n50673.000000\n0.712296\n0.373744\n1.000000\n\n\n75%\n1.000000\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n1.000000\n0.938827\n0.090882\n0.369132\n2.660000\n66005.000000\n0.816798\n0.530036\n1.000000\n\n\nmax\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n...\n1.000000\n1.000000\n1.000000\n0.989622\n0.997544\n5.270000\n200001.000000\n1.000000\n1.000000\n1.000000\n\n\n\n\n8 rows × 48 columns\n\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of their randomization mechanism, I have provided a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically different from one another.\nI have created a function called t_test_calc that calculates the t-statistic and the p-value to determine if there is a statistically signigicant difference between the variables in the treatment and test groups at a pre-determined confidence interval.\n\ndef t_test_calc(data, treatment_col, control_col, outcome_col):\n    treatment = data[data[treatment_col] == 1]\n    control = data[data[control_col] == 1]\n    mean_treatment = treatment[outcome_col].mean()\n    mean_control = control[outcome_col].mean()\n    diff_means = mean_treatment - mean_control\n    std_treatment = treatment[outcome_col].std()\n    std_control = control[outcome_col].std()\n    n_treatment = treatment[outcome_col].count()\n    n_control = control[outcome_col].count()\n    t_stat = diff_means / np.sqrt((std_treatment**2/n_treatment) + (std_control**2/n_control))\n\n    return t_stat, n_treatment, n_control\n### T-stat calculation for mrm2 Variable###\nt_stat_mrm2, n_treatment, n_control = t_test_calc(karlan_df, \"treatment\", \"control\", \"mrm2\")\ndof = n_treatment + n_control - 2\n\np_value1 = (1 - t.cdf(np.abs(t_stat_mrm2), dof)) * 2\n\nprint(f\"t-stat calculated for mrm2: {t_stat_mrm2:.4f}\")\nprint(f\"p-value calculated for mrm2: {p_value1:.4f}\")\n\n### T-stat calculation for Freq Variable###\nt_stat_freq, n_treatment, n_control = t_test_calc(karlan_df, \"treatment\", \"control\", \"freq\")\ndof_freq = n_treatment + n_control - 2\n\np_value_freq = (1 - t.cdf(np.abs(t_stat_freq), dof)) * 2\n\nprint(f\"t-stat calculated for freq: {t_stat_freq:.4f}\")\nprint(f\"p-value calculated for freq:{p_value_freq:.4f}\")\n\nt-stat calculated for mrm2: 0.1195\np-value calculated for mrm2: 0.9049\nt-stat calculated for freq: -0.1108\np-value calculated for freq:0.9117\n\n\n\n##Linear regression for mrm2 and Freq variables\nfrom sklearn.linear_model import LinearRegression\nkarlan_df.fillna({\"mrm2\": 0}, inplace=True)\n\nX = karlan_df[['treatment']]  # Feature\ny = karlan_df['mrm2']  # Target variable\n\nmodel = LinearRegression()\nmodel.fit(X, y)\n\nprint('Coefficients for mrm2:', model.coef_)\nprint('Intercept for mrm2:', model.intercept_)\n\nCoefficients for mrm2: [0.01329623]\nIntercept for mrm2: 12.99814226643495\n\n\nAbove, I have tested the variable mrm2 & freq to see if there is a statistically significant difference between the treatment and control groups at a 95% confidence interval level. The variables mrm2 and freq represent the Number of Months since last donation and the number of prior dontations, respectively. Using the t-test-calc function, the calculated t-stat for mrm2 is 0.1195 and the p-value is 0.9049. This p-value is greater than the alpha value of 0.005, which means that we fail to reject the null hypothesis, and indicates that there is not enough evidence to conclude a statistically significant difference between the treatment and control groups when examining the number of months since their last donation, or the mrm2 variable.\nFor the freq variable, the t_stat and p_value calculated were -0.1108 and 0.9117, respectively. The calculated p-value of 0.9117 is greater than the alpha value of 0.05, and we once again fail to reject the null hypothesis. This indicates that there is not enough evidence to indicate a statistically significant difference between the treatment and control groups when comparing the donation frequency. These values are similar to those included in table 1 of Karlan et al. I believe table 1 was included in the paper to show the sample statistics of the member activity, census demographics and the state-level activity of organization."
  },
  {
    "objectID": "projects/project1/projects_files/mediabag/index.html#simulation-experiment",
    "href": "projects/project1/projects_files/mediabag/index.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\np_control = 0.018\np_treatment = 0.022\n\nnum_draws = 10000\n\ncumulative_average = np.zeros(num_draws)\ntotal_difference = 0\n\nfor i in range(num_draws):\n    control_draw = np.random.binomial(1, p_control)\n    treatment_draw = np.random.binomial(1, p_treatment)\n    difference = treatment_draw - control_draw\n    total_difference += difference\n    cumulative_average[i] = total_difference / (i + 1)\n\n\nplt.plot(cumulative_average, color='blue')\nplt.axhline(y=p_treatment - p_control, color='red', linestyle='--', label='True Difference')\nplt.xlabel('Number of Draws')\nplt.ylabel('Cumulative Average of Difference')\nplt.title('Cumulative Average of Difference in Proportions')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nWe initialize an array cumulative_average to store the cumulative average of the differences. We iterate through each draw, simulate draws from the Bernoulli distributions, calculate the difference in proportions, update the total difference, and calculate the cumulative average. We plot the cumulative average of the differences and add a horizontal dashed line to represent the true difference in means. This graph is indicating that as the number of draws increases,\nAs evident in the graph, as the number of draws increases, the cumulative average of the difference in proportions becomes more stable and approaches the true difference in means. This demonstrates that as the sample size becomes larger, the estimate of the difference in means becomes more accurate and reliable. Therefore, as the sample size increases, the random sampling variability decreases, which indicates that the larger samples provide more precise estimates of population parameters and allows statisticians to make more explicit causal claims in experimentation. (assuming that all other statistical theories are upheld)\n\n\nCentral Limit Theorem\n\np_control = 0.018\np_treatment = 0.022\n\n\nsample_sizes = [50, 200, 500, 1000]\nnum_simulations = 1000\n\naverage_differences = {}\n\nfor n in sample_sizes:\n    average_differences[n] = []\n    for _ in range(num_simulations):\n        control_draws = np.random.binomial(1, p_control, size=n)\n        treatment_draws = np.random.binomial(1, p_treatment, size=n)\n        average_difference = np.mean(treatment_draws) - np.mean(control_draws)\n        average_differences[n].append(average_difference)\n\nplt.figure(figsize=(12, 8))\nfor i, n in enumerate(sample_sizes):\n    plt.subplot(2, 2, i+1)\n    plt.hist(average_differences[n], bins=30, color='blue', alpha=0.7, orientation='horizontal')\n    plt.ylabel('Average Difference')\n    plt.xlabel('Frequency')\n    plt.title(f'Sample Size = {n}')\n    plt.axhline(y=0, color='red', linestyle='--')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThe histograms show the distribution of sample averages, which are the averages of a large number of samples taken from the population. According to the Central Limit Theorem, regardless of the shape of the population distribution, the distribution of sample averages tends to be normal (bell-shaped) as the sample size increases.\nIn a normal distribution, the mean (average) is located at the center of the distribution. As we increase the sample size, the distribution of sample averages becomes increasingly normal, and the mean of this distribution approaches the true population mean. Since we’re plotting the distribution of sample averages, and zero represents the mean difference (which would be the population mean difference if the samples were large enough), it’s expected that zero would be located in the center or “middle” of the distribution.\nTherefore, in the histograms representing the Central Limit Theorem, zero typically represents the “middle” of the distribution. As the sample size increases, the distribution becomes more concentrated around zero, indicating that the sample averages are more likely to be close to the true population mean difference."
  },
  {
    "objectID": "projects/project1/projects_files/mediabag/index.html#experimental-results",
    "href": "projects/project1/projects_files/mediabag/index.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyzed whether matched donations lead to an increased response rate of making a donation.\n\nimport matplotlib as plt\nfrom matplotlib import rcParams\n\nkarlan_df_copy = karlan_df.copy()\nkarlan_grouped = karlan_df.groupby([\"treatment\", \"control\"])[\"gave\"].mean()\nax = karlan_grouped.plot(kind='bar', color = [\"purple\", \"orange\"])\n\nrcParams['font.family'] = 'serif'  # Change 'serif' to the desired font family\nrcParams['font.serif'] = ['Avenir'] \nax.set_xlabel(\"Treatment and Control\")\nax.set_ylabel(\"Proportion of People who Donated\")\n\nax.set_title(\"Proportion of People who Donated in Treatment and Control\")\n\ngroup_labels = ['Treatment', 'Control']\nax.set_xticklabels(group_labels, rotation = 0)\n\nfor i, v in enumerate(karlan_grouped):\n    ax.text(i, v, f'{v:.4f}', ha='center', va='bottom')\n\n\n\n\n\n\n\n\nI also ran a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made, in addition to running a bivariate linear regression to demonstrate the same finding.\n\nfrom scipy.stats import ttest_ind\nimport scipy.stats as stats\nkarlan_treatment = karlan_df[karlan_df[\"treatment\"] == 1]\nkarlan_control = karlan_df[karlan_df[\"control\"] == 1]\nt_statistic, p_value = stats.ttest_ind(karlan_treatment[\"gave\"], karlan_control[\"gave\"])\n\nprint(\"T-statistic:\", t_statistic)\nprint(\"p-value:\", p_value)\n\n#Bivariate Linear regression on gave\nX = karlan_df[['treatment']]  # Features\ny = karlan_df['gave']  # Target variable\n\nmodel = LinearRegression()\nmodel.fit(X, y)\n\nprint('Coefficients:', model.coef_)\nprint('Intercept:', model.intercept_)\n\nT-statistic: 3.101361000543946\np-value: 0.0019274025949016988\nCoefficients: [0.00418035]\nIntercept: 0.017858212980165173\n\n\nThe output indicates a t-statistic of approximately 3.10 and a p-value of approximately 0.002.\nIn interpreting these results, it’s important to recall that the t-statistic measures the size of the difference between the treatment and control groups relative to the variability in the data. Thus, the larger the t-statistic, the more the means of the two groups differ. In this case, a t-statistic of 3.10 suggests a substantial difference between the means of the treatment and control groups.\nThe p-value, on the other hand, assesses the probability of observing such a large difference if there were no true difference between the treatment and control groups (i.e., if the null hypothesis were true). A small p-value (in this case, 0.002) indicates that the observed difference is unlikely to have occurred by random chance alone. Interpreted in the context of the experiment, these statistical results suggest that there is a statistically significant difference in charitable giving between the treatment and control groups. In other words, the intervention or treatment likely had an effect on the behavior of individuals in the treatment group compared to those in the control group.\nTherefore, this finding may imply that the certain interventions or nudges implemented in the treatment group, the matching and challenge grant letters, were effective in encouraging charitable giving behavior. Understanding the effectiveness of these interventions sheds light on the psychological mechanisms and motivations behind charitable giving, potentially informing future strategies for promoting philanthropy and altruism.\n\nProbit Regression\nNext I ran a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable was assesment to treatment or control.\n\n#Probit Regression\nimport statsmodels.api as sm\n\nX = karlan_df[['treatment', 'control']]\ny = karlan_df['gave']\n\nmodel = sm.Probit(y, X).fit()\n\nprint(model.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Tue, 16 Apr 2024   Pseudo R-squ.:               0.0009783\nTime:                        22:18:49   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\ntreatment     -2.0134      0.015   -131.734      0.000      -2.043      -1.983\ncontrol       -2.1001      0.023    -90.073      0.000      -2.146      -2.054\n==============================================================================\n\n\nProbit regression is a type of regression analysis used to model binary outcomes, similar to logistic regression. In probit regression, the relationship between the predictor variables and the binary outcome is modeled using the cumulative distribution function of the standard normal distribution (also known as the probit function). The model assumes that the linear combination of predictor variables is associated with the probability of the binary outcome.\n\n\n\nDifferences between Match Rates\nNext, I assessed the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\n\n# T-test for ratio2 (2:1 match) compared to 1:1 match\nt_stat_ratio2, p_value_ratio2 = ttest_ind(karlan_df[karlan_df['ratio2'] == 1]['gave'], karlan_df[karlan_df['ratio2'] == 0]['gave'])\n\n# T-test for ratio3 (3:1 match) compared to 1:1 match\nt_stat_ratio3, p_value_ratio3 = ttest_ind(karlan_df[karlan_df['ratio3'] == 1]['gave'], karlan_df[karlan_df['ratio3'] == 0]['gave'])\n\nprint(\"T-Test Results for 2:1 match ratio:\")\nprint(f\"T-Statistic: {t_stat_ratio2}, P-Value: {p_value_ratio2}\")\n\nprint(\"\\nT-Test Results for 3:1 match ratio:\")\nprint(f\"T-Statistic: {t_stat_ratio3}, P-Value: {p_value_ratio3}\")\n\nT-Test Results for 2:1 match ratio:\nT-Statistic: 1.6725548025261596, P-Value: 0.09442121711611902\n\nT-Test Results for 3:1 match ratio:\nT-Statistic: 1.7562202653799, P-Value: 0.07905691730335489\n\n\nOverall, based on these results, we do not have enough evidence to conclude that either the 2:1 match ratio or the 3:1 match ratio has a significantly different effect on charitable donations compared to the 1:1 match ratio. These findings match those of Karlan et al. They too found that “that neither the match threshold nor the example amount had a meaningful influence on behavior.”\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\n\nimport pyrsm as rsm\n\nreg_ratio = rsm.model.regress(\n    data = {\"Karlan DF\": karlan_df},\n    rvar = \"gave\",\n    evar = \"ratio\"\n)\n\nreg_ratio.summary()\n\nLinear regression (OLS)\nData                 : Karlan DF\nResponse variable    : gave\nExplanatory variables: ratio\nNull hyp.: the effect of x on gave is zero\nAlt. hyp.: the effect of x on gave is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.018      0.001   16.225  &lt; .001  ***\nratio[1]         0.003      0.002    1.661   0.097    .\nratio[2]         0.005      0.002    2.744   0.006   **\nratio[3]         0.005      0.002    2.802   0.005   **\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: 0.0\nF-statistic: 3.665 df(3, 50079), p.value 0.012\nNr obs: 50,083\n\n\nIn this regression, each ratio coefficient represents the effect of the corresponding ratio variable on charitable donations, holding other variables constant. Ratio[1]: The coefficient is positive (0.003), but it is not statistically significant at the 0.05 significance level (p = 0.097). Ratio[2]: The coefficient is positive (0.005) and statistically significant (p = 0.006), indicating that for each unit increase in ratio[2], charitable donations increase by 0.005 units, holding other variables constant. Ratio[3]: Similar to Ratio[2], the coefficient is positive (0.005) and statistically significant (p = 0.005), suggesting that for each unit increase in ratio[3], charitable donations increase by 0.005 units, holding other variables constant. The intercept represents the expected value of the dependent variable (charitable donations) when all explanatory variables (ratio) are zero. In this case, the intercept is statistically significant (p &lt; 0.001), indicating that when the ratio is zero, there is still a non-zero expected value of charitable donations.\nThe R-squared value (0.0) indicates that the model does not explain much of the variability in charitable donations. The F-statistic (3.665) tests the overall significance of the model. With a p-value of 0.012, the model is statistically significant, suggesting that at least one of the explanatory variables has a significant effect on charitable donations.\nOverall, the results suggest that ratio[2] and ratio[3] have a statistically significant positive effect on charitable donations, while ratio[1] does not have a statistically significant effect. However, it’s essential to consider the context of the study and potential limitations when interpreting these findings.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n# Calculate response rate difference between 1:1 and 2:1 match ratios\nresponse_rate_1_1 = len(karlan_df[(karlan_df['ratio'] == 1) & (karlan_df['gave'] == 1)]) / len(karlan_df[karlan_df['ratio'] == 1])\nresponse_rate_2_1 = len(karlan_df[(karlan_df['ratio'] == 2) & (karlan_df['gave'] == 1)]) / len(karlan_df[karlan_df['ratio'] == 2])\nresponse_rate_difference_1_2 = response_rate_2_1 - response_rate_1_1\n\n# Calculate response rate difference between 2:1 and 3:1 match ratios\nresponse_rate_3_1 = len(karlan_df[(karlan_df['ratio'] == 3) & (karlan_df['gave'] == 1)]) / len(karlan_df[karlan_df['ratio'] == 3])\nresponse_rate_difference_2_3 = response_rate_3_1 - response_rate_2_1\n\nprint(\"Response Rate Difference between 1:1 and 2:1 Match Ratios:\", response_rate_difference_1_2)\nprint(\"Response Rate Difference between 2:1 and 3:1 Match Ratios:\", response_rate_difference_2_3)\n\n\n### \n\ncoefficient_ratio_1 = 0.003\ncoefficient_ratio_2 = 0.005\ncoefficient_ratio_3 = 0.005\n\n# Calculate response rate difference between 1:1 and 2:1 match ratios\nresponse_rate_difference_coef_1_2 = coefficient_ratio_2 - coefficient_ratio_1\n\n# Calculate response rate difference between 2:1 and 3:1 match ratios\nresponse_rate_difference_coef_2_3 = coefficient_ratio_3 - coefficient_ratio_2\n\nprint(\"Response Rate Difference (from Coefficients) between 1:1 and 2:1 Match Ratios:\", response_rate_difference_coef_1_2)\nprint(\"Response Rate Difference (from Coefficients) between 2:1 and 3:1 Match Ratios:\", response_rate_difference_coef_2_3)\n\nResponse Rate Difference between 1:1 and 2:1 Match Ratios: 0.0018842510217149944\nResponse Rate Difference between 2:1 and 3:1 Match Ratios: 0.00010002398025293902\nResponse Rate Difference (from Coefficients) between 1:1 and 2:1 Match Ratios: 0.002\nResponse Rate Difference (from Coefficients) between 2:1 and 3:1 Match Ratios: 0.0\n\n\nResponse Rate Difference between 1:1 and 2:1 Match Ratios:\n    Direct Data Analysis: The response rate difference between individuals in the 1:1 match ratio group and the 2:1 match ratio group is approximately 0.0019 (or 0.19%).\n    Coefficient Analysis: The response rate difference (derived from the coefficients) between the 1:1 match ratio group and the 2:1 match ratio group is 0.002 (or 0.2%).\n\nResponse Rate Difference between 2:1 and 3:1 Match Ratios:\n    Direct Data Analysis: The response rate difference between individuals in the 2:1 match ratio group and the 3:1 match ratio group is approximately 0.0001 (or 0.01%).\n    Coefficient Analysis: The response rate difference (derived from the coefficients) between the 2:1 match ratio group and the 3:1 match ratio group is 0.0 (or no difference).\nInterpretation:\n1:1 vs. 2:1 Match Ratios:\n    Both the direct data analysis and the coefficient analysis suggest that individuals in the 2:1 match ratio group have a slightly higher response rate compared to those in the 1:1 match ratio group. The difference is small but consistent across both analyses.\n\n2:1 vs. 3:1 Match Ratios:\n    According to the direct data analysis, there is almost no difference in the response rates between the 2:1 match ratio group and the 3:1 match ratio group. However, the coefficient analysis indicates that the response rate difference between these groups is exactly zero.\nOverall, based on these findings, it seems that increasing the size of matched donations from 1:1 to 2:1 may lead to a slightly higher response rate, but further increasing the match ratio beyond 2:1 may not have a significant additional impact on the response rate.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyzed the effect of the size of matched donation on the size of the charitable contribution.\n\nfrom scipy.stats import ttest_ind\n\n# Assuming your DataFrame is named karlan_df and it contains columns 'treatment' and 'amount'\n\n# Separate the donation amounts for treatment and control groups\ntreatment_amount = karlan_df[karlan_df['treatment'] == 1]['amount']\ncontrol_amount = karlan_df[karlan_df['treatment'] == 0]['amount']\n\n# Perform the t-test\nt_statistic, p_value = ttest_ind(treatment_amount, control_amount)\n\n# Print the results\nprint(\"T-statistic:\", t_statistic)\nprint(\"P-value:\", p_value)\n\nT-statistic: 1.8605020225753781\nP-value: 0.06282038947470683\n\n\nT-test Approach: If the p-value from the t-test is less than a chosen significance level (e.g., 0.05), it indicates that there is a statistically significant difference in donation amounts between the treatment and control groups. This suggests that treatment status, such as the use of a matching grant letter or challenge grant letter, does have a statistically significant effect on donation amounts.\nBivariate Linear Regression Approach: If the coefficient for the ‘treatment’ variable in the linear regression model is statistically significant (p-value &lt; 0.05), it indicates that treatment status has a significant effect on donation amounts. The sign of the coefficient indicates the direction of the effect (positive or negative), and the magnitude represents the size of the effect.\nBoth the t-test approach and the Bivariate Linear Regression approach provide insights into the relationship between the treatment status and donation amounts. They help in understanding whether being in the treatment group influences the donation amounts compared to the control group.\n\ndonated_df = karlan_df[karlan_df['amount'] &gt; 0]\n#added a constant term for the intercept\ndonated_df['intercept'] = 1\nX = donated_df[['intercept', 'treatment']]\ny = donated_df['amount']\n\nmodel = sm.OLS(y, X).fit()\n\n\nprint(model.summary())\n###\n\ntreatment_amount = donated_df[donated_df['treatment'] == 1]['amount']\ncontrol_amount = donated_df[donated_df['treatment'] == 0]['amount']\n\n\nt_statistic, p_value = ttest_ind(treatment_amount, control_amount)\n\nprint(\"T-statistic:\", t_statistic)\nprint(\"P-value:\", p_value)\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.001\nMethod:                 Least Squares   F-statistic:                    0.3374\nDate:                Tue, 16 Apr 2024   Prob (F-statistic):              0.561\nTime:                        22:18:50   Log-Likelihood:                -5326.8\nNo. Observations:                1034   AIC:                         1.066e+04\nDf Residuals:                    1032   BIC:                         1.067e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept     45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\nOmnibus:                      587.258   Durbin-Watson:                   2.031\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5623.279\nSkew:                           2.464   Prob(JB):                         0.00\nKurtosis:                      13.307   Cond. No.                         3.49\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\nT-statistic: -0.5808388615237938\nP-value: 0.5614758782284279\n\n\n/var/folders/bj/t618x2614s9c896326lrdjw40000gn/T/ipykernel_92013/1712922690.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  donated_df['intercept'] = 1\n\n\nBased on these results, we can conclude that there is no significant difference in the amount donated by individuals in the treatment group compared to those in the control group. Therefore, the treatment coefficient does not have a causal interpretation regarding the effectiveness of the treatment on the amount donated. It suggests that the treatment (whatever it may be) does not significantly influence the donation amount.\n\nimport matplotlib.pyplot as plt\n\n#filtering the dataset for if a donation was made\ndonated_treatment = karlan_df[(karlan_df['amount'] &gt; 0) & (karlan_df['treatment'] == 1)]\ndonated_control = karlan_df[(karlan_df['amount'] &gt; 0) & (karlan_df['treatment'] == 0)]\n\n# sample averages for control and treatment\navg_treatment = donated_treatment['amount'].mean()\navg_control = donated_control['amount'].mean()\n\n# create histograms\nplt.figure(figsize=(10, 5))\n\n#histogram for treatment group\nplt.subplot(1, 2, 1)\nplt.hist(donated_treatment['amount'], color='blue', alpha=0.7)\nplt.axvline(avg_treatment, color='red', linestyle='dashed', linewidth=1, label='Sample Average')\nplt.xlabel('Donation Amount')\nplt.ylabel('Frequency')\nplt.title('Treatment Group')\nplt.legend()\n\n# histogram for control group\nplt.subplot(1, 2, 2)\nplt.hist(donated_control['amount'], color='green', alpha=0.7)\nplt.axvline(avg_control, color='red', linestyle='dashed', linewidth=1, label='Sample Average')\nplt.xlabel('Donation Amount')\nplt.ylabel('Frequency')\nplt.title('Control Group')\nplt.legend()\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Madeline Sands",
    "section": "Education",
    "text": "Education\nUniversity of California, San Diego | San Diego, CA Masters of Science in Business Analytics | July 2023 - December 2015\nUniversity of California, Irvine | Irvine, CA B.S in Analytical Chemistry | Sept 2015 - March 2020"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Madeline Sands",
    "section": "Experience",
    "text": "Experience"
  }
]