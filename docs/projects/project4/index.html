<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.553">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Madeline Sands">
<meta name="dcterms.date" content="2024-05-26">

<title>Madeline Sands - Key Drivers Analysis</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Madeline Sands</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../resume.html"> 
<span class="menu-text">Resume</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../projects.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#background-on-variable-importance-and-key-drivers-analysis" id="toc-background-on-variable-importance-and-key-drivers-analysis" class="nav-link active" data-scroll-target="#background-on-variable-importance-and-key-drivers-analysis">1. Background on Variable Importance and Key Drivers Analysis</a>
  <ul class="collapse">
  <li><a href="#key-driver-analysis-methods-from-linear-regression-models" id="toc-key-driver-analysis-methods-from-linear-regression-models" class="nav-link" data-scroll-target="#key-driver-analysis-methods-from-linear-regression-models">Key Driver Analysis Methods from Linear Regression Models</a></li>
  <li><a href="#methods-derived-from-game-theory" id="toc-methods-derived-from-game-theory" class="nav-link" data-scroll-target="#methods-derived-from-game-theory">Methods Derived from Game Theory</a></li>
  <li><a href="#methods-derived-from-decision-trees-and-ensemble-models" id="toc-methods-derived-from-decision-trees-and-ensemble-models" class="nav-link" data-scroll-target="#methods-derived-from-decision-trees-and-ensemble-models">Methods Derived from Decision Trees and Ensemble Models</a></li>
  <li><a href="#data-processing" id="toc-data-processing" class="nav-link" data-scroll-target="#data-processing">2. Data processing</a></li>
  <li><a href="#key-driver-analysis-and-interpretation" id="toc-key-driver-analysis-and-interpretation" class="nav-link" data-scroll-target="#key-driver-analysis-and-interpretation">3. Key Driver Analysis and Interpretation</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Key Drivers Analysis</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Madeline Sands </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">May 26, 2024</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<p>This post explains and implements a few measures of variable importance for features of a payment card and their impact on customer satisfaction with that payment card.</p>
<section id="background-on-variable-importance-and-key-drivers-analysis" class="level2">
<h2 class="anchored" data-anchor-id="background-on-variable-importance-and-key-drivers-analysis">1. Background on Variable Importance and Key Drivers Analysis</h2>
<p>Variable importance and key drivers analysis are often used in conjunction when determining which variables contribute the most to a model’s predictive power. Different supervised machine learning models use various methods to calculate variable importance, with the same goal of trying to see which explanatory variable has the greatest impact on the response variable. We will review these different methods to identify variable importance below and implement them using a dataset examining customer satisfaction with a payment card.</p>
<section id="key-driver-analysis-methods-from-linear-regression-models" class="level3">
<h3 class="anchored" data-anchor-id="key-driver-analysis-methods-from-linear-regression-models">Key Driver Analysis Methods from Linear Regression Models</h3>
<section id="pearsons-correlation" class="level4">
<h4 class="anchored" data-anchor-id="pearsons-correlation">Pearsons Correlation</h4>
<p>In linear regression models, key drivers can be identified via the change in the value of the <strong>Pearson Correlation Coefficient</strong>. Pearson’s correlation coefficient is a measure used to quantify the linear relationship between two variables, and ranges from -1 to +1. A coefficient of +1 indicates a perfect positive linear relationship whereas -1 indicates a perfect negative linear relationship. 0 indicates no linear correlation.</p>
<p>Suppose we have 3 explanatory variables as part of our linear regression model. We can remove one variable at a time and recalculate our Pearson’s Correlation value. Features with high absolute values of the correlation coefficient (close to 1 or -1) are likely more important to our model’s predictive power because they have a strong linear relationship with the target variable. The sign can also indicate the direction of the relationship. A positive sign means that as the feature increases, the target increases and vice versa for the negative sign. We can use the correlation coefficient to rank the features based on the absolute value of their respective coefficients, thus features with higher absolute values are generally more influential in predicting the target variable in a linear regression context.</p>
<p>When calculating Pearon’s we take the covariance of 2 variables, and divide it by the product of their standard deviations. This formula inherently standardizes the covariance, meaning that Pearson’s correlation coefficient itself is already a standardized measure. Therefore, when implementing pearson’s, you do not need to standardize your data before finding the coefficient values.</p>
<p>However, it is critical to note that while strong correlations with the target variable are important, it’s also crucial to check the correlations between features. High correlation between features, i.e.&nbsp;multicollinearity, can affect the model’s stability and the interpretation of the coefficients.</p>
</section>
<section id="usefullness" class="level4">
<h4 class="anchored" data-anchor-id="usefullness">Usefullness</h4>
<p>Usefulnes is another measure derived from linear regression models. “Usefulness” or <span class="math inline">\({\Delta}R^2\)</span>, measures the impact of individual features on the performance of a regression model by observing how the model’s <span class="math inline">\(R^2\)</span> value changes when a feature is dropped. This technique is valuable because it can reveal the contribution of a specific feature to the overall explanatory power of the model, beyond a simple correlation. It is also a relatively straightforward to run.</p>
<p>However, there are some considerations to take into account when using the <span class="math inline">\({\Delta}R^2\)</span> to evaluate key drivers, specifically relating to interactions and non-linearity between the features, similar to Pearson’s. The change in <span class="math inline">\(R^2\)</span> doesn’t account for interactions between features unless specifically modeled. Therefore, if there is an interaction between 2 variables, that would have to be explicilty included in a linear regression model for it to have an impact on the <span class="math inline">\(R^2\)</span> value. Also, non-linear relationships might not be captured effectively. If features are highly correlated, removing one might not show a significant change in <span class="math inline">\(R^2\)</span> because its effect is being captured by the correlated features.</p>
</section>
</section>
<section id="methods-derived-from-game-theory" class="level3">
<h3 class="anchored" data-anchor-id="methods-derived-from-game-theory">Methods Derived from Game Theory</h3>
<section id="shapley-values" class="level4">
<h4 class="anchored" data-anchor-id="shapley-values">Shapley Values</h4>
<p>Shapley values are a concept derived from cooperative game theory used to fairly allocate the “payout” among players depending on their contribution to the total game. In the context of machine learning, Shapley values can be used to explain the contribution of each feature to the model’s prediction. Shapley values provide a detailed breakdown of how each feature contributes to the final prediction, which can often be more insightful than measures like the pearsons coefficients or <span class="math inline">\({\Delta}R^2\)</span>.</p>
<p>When computing Shapley values, the need to standardize data before computing Shapley values largely depends on the type of predictive model used. For linear regression models, standardizing might not be necessary for interpreting the contribution of features, as the model is fairly transparent and the contribution of features can be directly observed from the regression coefficients. However, if we are running and creating more complex models like neural networks or ensemble models (e.g., random forests, gradient boosting machines), standardizing features can help in comparing their contributions on a common scale, especially if the features vary widely in scale and units. Finally, regardless of the model, standardizing features can make the interpretation of Shapley values more straightforward across different features. When features are on the same scale, their Shapley values are easier to compare, as no single feature will dominate simply because of differences in scale.</p>
</section>
<section id="johnsons-relative-weights" class="level4">
<h4 class="anchored" data-anchor-id="johnsons-relative-weights">Johnson’s Relative weights</h4>
<p>Johnson’s relative weights analysis is a statistical technique used to determine the importance of predictor variables in a regression model, especially when dealing with multicollinearity among predictors. This method decomposes the total variance explained by the model into portions attributable to each predictor, taking into account the intercorrelations among them.</p>
<p>Johnson’s relative weights transform the raw regression coefficients by considering the correlation matrix of the predictors and results in a set of weights that reflect the contribution of each predictor to the model’s predictive power. Johnson’s weights provide a more nuanced view of feature importance than simple correlation or regression coefficients alone, particularly useful in models where predictors are not independent.</p>
<p>When computing Johnson’s relative weights, it is generally recommended to standardize the variables. Standardization ensures that each predictor contributes to the regression model on a comparable scale. This is crucial because Johnson’s Relative Weights are used to interpret the proportion of explained variance in the dependent variable that can be attributed to each independent variable. If the variables are not standardized, their weights might reflect their scale rather than their actual contribution to the model. Standardization removes this disparity, allowing a fair assessment of each variable’s relative importance based on their contribution to the model’s predictive power rather than their scale.</p>
</section>
</section>
<section id="methods-derived-from-decision-trees-and-ensemble-models" class="level3">
<h3 class="anchored" data-anchor-id="methods-derived-from-decision-trees-and-ensemble-models">Methods Derived from Decision Trees and Ensemble Models</h3>
<section id="decision-trees-and-gini-importance" class="level4">
<h4 class="anchored" data-anchor-id="decision-trees-and-gini-importance">Decision Trees and Gini Importance</h4>
<p>In Decision Trees and Ensemeble Models (such as Random Forest or Gradient boosting) methods such as <strong>Gini Importance</strong> and <strong>Permutation Importance</strong> are used to determine this varibale importance. <strong>Gini Importance</strong> - Measures how much each feature decreases the impurity in a decision tree, averaged over all trees in the ensemble. <strong>Permutation Importance</strong> - Measures the decrease in model performance (such as via accuracy or Root mean squared error) when the values of a feature are randomly shuffled, breaking the relationship between the feature and the target.</p>
<p>By understanding variable importance and conducting key drivers analysis, organizations can make data-driven decisions, prioritize resources, and develop strategies that target the most impactful factors.</p>
<p>When creating decision trees and computing the Gini Importance, standardizing the data beforehand is not necessary and generally doesn’t enhance the performance or interpretability of the model.</p>
</section>
</section>
<section id="data-processing" class="level3">
<h3 class="anchored" data-anchor-id="data-processing">2. Data processing</h3>
<div id="04b79962" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyrsm <span class="im">as</span> rsm </span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> pearsonr</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> shap</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> textwrap <span class="im">import</span> wrap</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>driver_analysis <span class="op">=</span> pd.read_csv(<span class="st">'data/data_for_drivers_analysis.csv'</span>)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>driver_analysis.head(<span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">brand</th>
<th data-quarto-table-cell-role="th">id</th>
<th data-quarto-table-cell-role="th">satisfaction</th>
<th data-quarto-table-cell-role="th">trust</th>
<th data-quarto-table-cell-role="th">build</th>
<th data-quarto-table-cell-role="th">differs</th>
<th data-quarto-table-cell-role="th">easy</th>
<th data-quarto-table-cell-role="th">appealing</th>
<th data-quarto-table-cell-role="th">rewarding</th>
<th data-quarto-table-cell-role="th">popular</th>
<th data-quarto-table-cell-role="th">service</th>
<th data-quarto-table-cell-role="th">impact</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1</td>
<td>98</td>
<td>3</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1</td>
<td>179</td>
<td>5</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1</td>
<td>197</td>
<td>3</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1</td>
<td>317</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>1</td>
<td>356</td>
<td>4</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>1</td>
<td>395</td>
<td>4</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>1</td>
<td>586</td>
<td>3</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>1</td>
<td>596</td>
<td>2</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">8</td>
<td>1</td>
<td>978</td>
<td>3</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">9</td>
<td>1</td>
<td>987</td>
<td>3</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<p>We are now going to see these methods in action. We are using a database that has 2553 observations across 9 variables, with the response variable being the <code>satisfaction</code> score. The following regressors are all binary variables:</p>
<ul>
<li><code>trust</code> - Is offered by a brand I trust</li>
<li><code>build</code> - Helps build credit quickly</li>
<li><code>differs</code> - Is different from other cards</li>
<li><code>easy</code> - Is easy to use</li>
<li><code>appealing</code> - Has appealing benefits or rewards</li>
<li><code>rewarding</code> - Rewards me for responsible usage</li>
<li><code>popular</code>- Is used by a lot of people</li>
<li><code>service</code> - Provides outstanding customer service</li>
<li><code>impact</code> - Makes a difference in my life</li>
</ul>
<p>Respondents were asked to respond <code>yes</code> or <code>no</code> to 9 questions related to attributes of a payment card. They then provided an overall satisfaction score from 1-5. We will use the methods above to determine which attributes contribute the highest to respondents overall satisfaction of the payment cards.</p>
<p>Before we demonstrate differences in the relative importance values, we need to first assess the multicollinearity between the variables. Due to the <strong>Halo Effect</strong>, we see that respondents tend to rate something higher on all attributes if they like a brand, but also rate something lower on all attributes if they dislike a brand. Therefore, we often see that in perception datasets, there is a high level of multicollinearity. Below, we will run a correlation matrix to see which variables are highly correlated with each other.</p>
<div id="4d27a082" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>correlation_matrix <span class="op">=</span> driver_analysis.corr()</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(correlation_matrix)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                 brand        id  satisfaction     trust     build   differs  \
brand         1.000000  0.001459     -0.049296 -0.119908 -0.083552 -0.143542   
id            0.001459  1.000000     -0.009228 -0.016797 -0.001620  0.008360   
satisfaction -0.049296 -0.009228      1.000000  0.255706  0.191896  0.184801   
trust        -0.119908 -0.016797      0.255706  1.000000  0.399652  0.306493   
build        -0.083552 -0.001620      0.191896  0.399652  1.000000  0.370705   
differs      -0.143542  0.008360      0.184801  0.306493  0.370705  1.000000   
easy         -0.155121  0.007316      0.212985  0.480973  0.443953  0.349693   
appealing    -0.209406 -0.000157      0.207997  0.420704  0.369456  0.418159   
rewarding    -0.151821  0.027222      0.194561  0.423868  0.435770  0.349758   
popular      -0.147349  0.006211      0.171425  0.389409  0.333667  0.266456   
service      -0.101800 -0.001923      0.251098  0.503966  0.407956  0.367615   
impact       -0.130475  0.038579      0.254539  0.354062  0.383639  0.416957   

                  easy  appealing  rewarding   popular   service    impact  
brand        -0.155121  -0.209406  -0.151821 -0.147349 -0.101800 -0.130475  
id            0.007316  -0.000157   0.027222  0.006211 -0.001923  0.038579  
satisfaction  0.212985   0.207997   0.194561  0.171425  0.251098  0.254539  
trust         0.480973   0.420704   0.423868  0.389409  0.503966  0.354062  
build         0.443953   0.369456   0.435770  0.333667  0.407956  0.383639  
differs       0.349693   0.418159   0.349758  0.266456  0.367615  0.416957  
easy          1.000000   0.432904   0.461316  0.387304  0.456976  0.412092  
appealing     0.432904   1.000000   0.481159  0.376080  0.425463  0.394282  
rewarding     0.461316   0.481159   1.000000  0.350825  0.457016  0.384245  
popular       0.387304   0.376080   0.350825  1.000000  0.378262  0.305265  
service       0.456976   0.425463   0.457016  0.378262  1.000000  0.412313  
impact        0.412092   0.394282   0.384245  0.305265  0.412313  1.000000  </code></pre>
</div>
</div>
<section id="pearson-correlation" class="level4">
<h4 class="anchored" data-anchor-id="pearson-correlation">Pearson Correlation</h4>
<div id="638179ed" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Standardizing the Driver Analysis Dataframe</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>da_standardized <span class="op">=</span> driver_analysis.copy().iloc[:, <span class="dv">2</span>:<span class="dv">12</span>]</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>da_standardized <span class="op">=</span> (da_standardized <span class="op">-</span> da_standardized.mean()) <span class="op">/</span> da_standardized.std()</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>da_standardized.head()</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co">#breaking out our Predictor and Dependent variables</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>X_standardized <span class="op">=</span> da_standardized[[<span class="st">"trust"</span>, <span class="st">"build"</span>, <span class="st">"differs"</span>, <span class="st">"easy"</span>, <span class="st">"appealing"</span>, <span class="st">"rewarding"</span>, <span class="st">"popular"</span>, <span class="st">"service"</span>, <span class="st">"impact"</span>]]</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>y_standardized <span class="op">=</span> da_standardized[<span class="st">'satisfaction'</span>]</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co">#Fit a linear regression model</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LinearRegression()</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>model.fit(X_standardized,y_standardized)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="co">#extract out coefficients and intercept from our linear regression model</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>coefficients <span class="op">=</span> model.coef_</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>intercept <span class="op">=</span> model.intercept_</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="75750c7a" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Creating an empty dictionary to store our coefficients in </span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>pearson_corr_matrix <span class="op">=</span> {}</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co">#extracting one coefficient at a time to calculate the correlation value of</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> column <span class="kw">in</span> da_standardized.columns:</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> column <span class="op">!=</span> <span class="st">'satisfaction'</span>:</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>        corr, _ <span class="op">=</span> pearsonr(da_standardized[column], da_standardized[<span class="st">'satisfaction'</span>])</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>        pearson_corr_matrix[column] <span class="op">=</span> corr</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>total_sum <span class="op">=</span> <span class="bu">sum</span>(pearson_corr_matrix.values())</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>percentage_data <span class="op">=</span> {}</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate and print the percentage of the sum for each value</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> key, value <span class="kw">in</span> pearson_corr_matrix.items():</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    percentage <span class="op">=</span> (value <span class="op">/</span> total_sum) <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    percentage_data[key] <span class="op">=</span> percentage</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the new dictionary to a DataFrame</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>pearson_corr_df <span class="op">=</span> pd.DataFrame(<span class="bu">list</span>(percentage_data.items()), columns<span class="op">=</span>[<span class="st">'Features'</span>, <span class="st">'Pearson_corr_%'</span>])</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>pearson_corr_df[<span class="st">"Pearson_corr_%"</span>] <span class="op">=</span> pearson_corr_df[<span class="st">"Pearson_corr_%"</span>].<span class="bu">round</span>(<span class="dv">1</span>)</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pearson_corr_df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    Features  Pearson_corr_%
0      trust            13.3
1      build            10.0
2    differs             9.6
3       easy            11.1
4  appealing            10.8
5  rewarding            10.1
6    popular             8.9
7    service            13.0
8     impact            13.2</code></pre>
</div>
</div>
</section>
<section id="standardized-regression-coefficients" class="level4">
<h4 class="anchored" data-anchor-id="standardized-regression-coefficients">Standardized Regression Coefficients</h4>
<div id="7ed53cb5" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>X_unstandardized <span class="op">=</span> driver_analysis[[<span class="st">"trust"</span>, <span class="st">"build"</span>, <span class="st">"differs"</span>, <span class="st">"easy"</span>, <span class="st">"appealing"</span>, <span class="st">"rewarding"</span>, <span class="st">"popular"</span>, <span class="st">"service"</span>, <span class="st">"impact"</span>]]</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>y_unstandardized <span class="op">=</span> driver_analysis[<span class="st">'satisfaction'</span>]</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>model_SLC <span class="op">=</span> LinearRegression()</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>model_SLC.fit(X_unstandardized, y_unstandardized)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>standardized_coefficients <span class="op">=</span> model_SLC.coef_</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>SLC_coefficients_df <span class="op">=</span> pd.DataFrame({<span class="st">'Predictor'</span>: X_standardized.columns, <span class="st">'Standardized Coefficient'</span>: standardized_coefficients})</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>total_sum_regression_coef <span class="op">=</span> SLC_coefficients_df[<span class="st">"Standardized Coefficient"</span>].<span class="bu">sum</span>()</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>SLC_coefficients_df[<span class="st">'SLC_Percent of Total'</span>] <span class="op">=</span> (SLC_coefficients_df[<span class="st">'Standardized Coefficient'</span>] <span class="op">/</span> total_sum_regression_coef) <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>SLC_coefficients_df[<span class="st">"SLC_Percent of Total"</span>] <span class="op">=</span> SLC_coefficients_df[<span class="st">"SLC_Percent of Total"</span>].<span class="bu">round</span>(<span class="dv">1</span>)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(SLC_coefficients_df)</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>SLC_df <span class="op">=</span> SLC_coefficients_df[[<span class="st">"Predictor"</span>, <span class="st">"SLC_Percent of Total"</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   Predictor  Standardized Coefficient  SLC_Percent of Total
0      trust                  0.272612                  24.8
1      build                  0.046960                   4.3
2    differs                  0.069159                   6.3
3       easy                  0.051623                   4.7
4  appealing                  0.079673                   7.3
5  rewarding                  0.011931                   1.1
6    popular                  0.039042                   3.6
7    service                  0.207591                  18.9
8     impact                  0.319789                  29.1</code></pre>
</div>
</div>
</section>
<section id="shapley-values-for-a-linear-regression" class="level4">
<h4 class="anchored" data-anchor-id="shapley-values-for-a-linear-regression">Shapley Values for a linear regression</h4>
<div id="a1d02f72" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the linear regression model</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>model_shapley <span class="op">=</span> LinearRegression()</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>model_shapley.fit(X_standardized, y_standardized)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the explainer</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>explainer <span class="op">=</span> shap.Explainer(model_shapley.predict, X_standardized)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate Shapley values</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>shap_values <span class="op">=</span> explainer(X_standardized)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Shapley values (if needed)</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>shap.summary_plot(shap_values, X_standardized)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>ExactExplainer explainer:  60%|█████▉    | 1521/2553 [00:00&lt;?, ?it/s]ExactExplainer explainer:  60%|██████    | 1541/2553 [00:10&lt;00:05, 181.33it/s]ExactExplainer explainer:  61%|██████    | 1560/2553 [00:10&lt;00:05, 167.44it/s]ExactExplainer explainer:  62%|██████▏   | 1584/2553 [00:10&lt;00:04, 197.48it/s]ExactExplainer explainer:  63%|██████▎   | 1608/2553 [00:10&lt;00:04, 212.03it/s]ExactExplainer explainer:  64%|██████▍   | 1631/2553 [00:10&lt;00:04, 218.06it/s]ExactExplainer explainer:  65%|██████▍   | 1653/2553 [00:10&lt;00:04, 207.89it/s]ExactExplainer explainer:  66%|██████▌   | 1674/2553 [00:10&lt;00:04, 204.13it/s]ExactExplainer explainer:  66%|██████▋   | 1696/2553 [00:10&lt;00:04, 207.26it/s]ExactExplainer explainer:  67%|██████▋   | 1719/2553 [00:10&lt;00:03, 211.21it/s]ExactExplainer explainer:  68%|██████▊   | 1741/2553 [00:11&lt;00:04, 171.45it/s]ExactExplainer explainer:  69%|██████▉   | 1764/2553 [00:11&lt;00:04, 186.26it/s]ExactExplainer explainer:  70%|██████▉   | 1787/2553 [00:11&lt;00:03, 197.24it/s]ExactExplainer explainer:  71%|███████   | 1808/2553 [00:11&lt;00:03, 190.73it/s]ExactExplainer explainer:  72%|███████▏  | 1830/2553 [00:11&lt;00:03, 197.02it/s]ExactExplainer explainer:  73%|███████▎  | 1851/2553 [00:11&lt;00:03, 194.67it/s]ExactExplainer explainer:  73%|███████▎  | 1871/2553 [00:11&lt;00:03, 182.78it/s]ExactExplainer explainer:  74%|███████▍  | 1891/2553 [00:11&lt;00:03, 184.95it/s]ExactExplainer explainer:  75%|███████▍  | 1910/2553 [00:12&lt;00:03, 176.14it/s]ExactExplainer explainer:  76%|███████▌  | 1929/2553 [00:12&lt;00:03, 179.50it/s]ExactExplainer explainer:  77%|███████▋  | 1954/2553 [00:12&lt;00:03, 194.56it/s]ExactExplainer explainer:  77%|███████▋  | 1976/2553 [00:12&lt;00:02, 198.48it/s]ExactExplainer explainer:  78%|███████▊  | 1996/2553 [00:12&lt;00:02, 197.43it/s]ExactExplainer explainer:  79%|███████▉  | 2017/2553 [00:12&lt;00:02, 197.54it/s]ExactExplainer explainer:  80%|███████▉  | 2037/2553 [00:12&lt;00:02, 197.03it/s]ExactExplainer explainer:  81%|████████  | 2057/2553 [00:12&lt;00:02, 192.06it/s]ExactExplainer explainer:  81%|████████▏ | 2077/2553 [00:12&lt;00:02, 183.14it/s]ExactExplainer explainer:  82%|████████▏ | 2096/2553 [00:13&lt;00:02, 177.68it/s]ExactExplainer explainer:  83%|████████▎ | 2116/2553 [00:13&lt;00:02, 182.43it/s]ExactExplainer explainer:  84%|████████▎ | 2135/2553 [00:13&lt;00:02, 170.80it/s]ExactExplainer explainer:  84%|████████▍ | 2157/2553 [00:13&lt;00:02, 182.08it/s]ExactExplainer explainer:  85%|████████▌ | 2178/2553 [00:13&lt;00:02, 186.70it/s]ExactExplainer explainer:  86%|████████▌ | 2197/2553 [00:13&lt;00:02, 142.24it/s]ExactExplainer explainer:  87%|████████▋ | 2213/2553 [00:13&lt;00:02, 135.43it/s]ExactExplainer explainer:  87%|████████▋ | 2229/2553 [00:13&lt;00:02, 141.11it/s]ExactExplainer explainer:  88%|████████▊ | 2245/2553 [00:14&lt;00:02, 133.90it/s]ExactExplainer explainer:  89%|████████▊ | 2260/2553 [00:14&lt;00:02, 135.45it/s]ExactExplainer explainer:  89%|████████▉ | 2283/2553 [00:14&lt;00:01, 158.80it/s]ExactExplainer explainer:  90%|█████████ | 2304/2553 [00:14&lt;00:01, 172.48it/s]ExactExplainer explainer:  91%|█████████ | 2324/2553 [00:14&lt;00:01, 179.96it/s]ExactExplainer explainer:  92%|█████████▏| 2351/2553 [00:14&lt;00:01, 199.55it/s]ExactExplainer explainer:  93%|█████████▎| 2373/2553 [00:14&lt;00:00, 204.14it/s]ExactExplainer explainer:  94%|█████████▍| 2394/2553 [00:14&lt;00:00, 199.59it/s]ExactExplainer explainer:  95%|█████████▍| 2417/2553 [00:14&lt;00:00, 207.25it/s]ExactExplainer explainer:  95%|█████████▌| 2438/2553 [00:14&lt;00:00, 206.79it/s]ExactExplainer explainer:  96%|█████████▋| 2462/2553 [00:15&lt;00:00, 214.06it/s]ExactExplainer explainer:  97%|█████████▋| 2484/2553 [00:15&lt;00:00, 202.37it/s]ExactExplainer explainer:  98%|█████████▊| 2505/2553 [00:15&lt;00:00, 168.58it/s]ExactExplainer explainer:  99%|█████████▉| 2523/2553 [00:15&lt;00:00, 171.41it/s]ExactExplainer explainer: 100%|█████████▉| 2544/2553 [00:15&lt;00:00, 181.27it/s]ExactExplainer explainer: 2554it [00:15, 66.07it/s]                           </code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-7-output-2.png" width="723" height="477" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="1e1c3a58" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Sum up the absolute values of Shapley values for each feature</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>feature_importance <span class="op">=</span> np.<span class="bu">sum</span>(shap_values.values, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the total sum of all Shapley values</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>total_importance <span class="op">=</span> np.<span class="bu">sum</span>(np.<span class="bu">abs</span>(feature_importance))</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the percentage contribution of each feature</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>percentage_contributions <span class="op">=</span> <span class="dv">100</span> <span class="op">*</span> feature_importance <span class="op">/</span> total_importance</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>percental_total <span class="op">=</span> percentage_contributions.<span class="bu">sum</span>()</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(percental_total)</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a DataFrame to display the results</span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>shapley_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Feature'</span>: X_standardized.columns,</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">'feature_importance'</span>: feature_importance,</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Shapley Value Sum'</span>: total_importance,</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Shapley_percent_Total'</span>: percentage_contributions</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>shapley_df[<span class="st">"Shapley_percent_Total"</span>] <span class="op">=</span> shapley_df[<span class="st">"Shapley_percent_Total"</span>].<span class="bu">round</span>(<span class="dv">1</span>)</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(shapley_df)</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>shapley_df_short <span class="op">=</span> shapley_df[[<span class="st">"Feature"</span>, <span class="st">"Shapley_percent_Total"</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>100.0
     Feature  feature_importance  Shapley Value Sum  Shapley_percent_Total
0      trust           35.362669         186.526379                   19.0
1      build            5.299767         186.526379                    2.8
2    differs           12.731269         186.526379                    6.8
3       easy            7.447898         186.526379                    4.0
4  appealing            8.891823         186.526379                    4.8
5  rewarding            1.071607         186.526379                    0.6
6    popular            1.380470         186.526379                    0.7
7    service           43.995915         186.526379                   23.6
8     impact           70.344962         186.526379                   37.7</code></pre>
</div>
</div>
</section>
<section id="usefulness" class="level4">
<h4 class="anchored" data-anchor-id="usefulness">Usefulness</h4>
<div id="a7cf2549" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>X_full <span class="op">=</span> sm.add_constant(X_unstandardized)  <span class="co"># Adding a constant term for the intercept</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>model_full <span class="op">=</span> sm.OLS(y_unstandardized, X_full).fit()</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>r2_full <span class="op">=</span> model_full.rsquared</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculating Delta R^2 for each feature</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>delta_r2 <span class="op">=</span> {}</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> feature <span class="kw">in</span> X_unstandardized.columns:</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    X_reduced <span class="op">=</span> sm.add_constant(X_unstandardized.drop(columns<span class="op">=</span>[feature]))  <span class="co"># Reduced model without the feature</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    model_reduced <span class="op">=</span> sm.OLS(y_unstandardized, X_reduced).fit()</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    r2_reduced <span class="op">=</span> model_reduced.rsquared</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>    delta_r2[feature] <span class="op">=</span> r2_full <span class="op">-</span> r2_reduced</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Output Delta R^2 values</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>delta_r2_df <span class="op">=</span> pd.DataFrame(delta_r2.items(), columns <span class="op">=</span>[<span class="st">"feature"</span>, <span class="st">"Delta R^2"</span>])</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>sum_r2 <span class="op">=</span> delta_r2_df[<span class="st">"Delta R^2"</span>].<span class="bu">sum</span>()</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>delta_r2_df[<span class="st">"Usefulness %"</span>] <span class="op">=</span> delta_r2_df[<span class="st">"Delta R^2"</span>] <span class="op">/</span> sum_r2 <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>delta_r2_df[<span class="st">"Usefulness %"</span>] <span class="op">=</span> delta_r2_df[<span class="st">"Usefulness %"</span>].<span class="bu">round</span>(<span class="dv">2</span>)</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>usefulness_df <span class="op">=</span> delta_r2_df[[<span class="st">"feature"</span>, <span class="st">"Usefulness %"</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="johnsons-relative-weights-epsilon" class="level4">
<h4 class="anchored" data-anchor-id="johnsons-relative-weights-epsilon">Johnson’s relative weights (Epsilon)</h4>
<div id="088878a8" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a linear regression model</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LinearRegression()</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>model.fit(X_unstandardized, y_unstandardized)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>r_squared <span class="op">=</span> model.score(X_unstandardized, y_unstandardized)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the correlation matrix of the standardized predictors</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>R <span class="op">=</span> np.corrcoef(X_unstandardized, rowvar<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Eigen decomposition</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>eigenvalues, eigenvectors <span class="op">=</span> np.linalg.eig(R)</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the relative importance</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>relative_importance <span class="op">=</span> eigenvectors<span class="op">**</span><span class="dv">2</span> <span class="op">*</span> eigenvalues[:, np.newaxis]</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>relative_contributions <span class="op">=</span> relative_importance.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>normalized_weights <span class="op">=</span> relative_contributions <span class="op">/</span> relative_contributions.<span class="bu">sum</span>()</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>normalized_sum <span class="op">=</span> normalized_weights.<span class="bu">sum</span>()</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the proportional contributions to R-squared</span></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>proportional_contributions <span class="op">=</span> normalized_weights <span class="op">*</span> r_squared</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the results</span></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pd.DataFrame({</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Feature'</span>: X_standardized.columns,</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Relative Contribution'</span>: proportional_contributions,</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Johnsons Epsilon'</span>: normalized_weights<span class="op">*</span><span class="dv">100</span></span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>results[<span class="st">"Johnsons Epsilon"</span>] <span class="op">=</span> results[<span class="st">"Johnsons Epsilon"</span>].<span class="bu">round</span>(<span class="dv">2</span>)</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>johnsons_df <span class="op">=</span> results[[<span class="st">"Feature"</span>, <span class="st">"Johnsons Epsilon"</span>]]</span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(johnsons_df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     Feature  Johnsons Epsilon
0      trust             11.39
1      build             11.37
2    differs             16.98
3       easy             12.90
4  appealing              7.46
5  rewarding              8.31
6    popular             10.88
7    service             13.37
8     impact              7.34</code></pre>
</div>
</div>
</section>
<section id="mean-decrease-in-the-gini-coefficient-from-a-random-forest" class="level4">
<h4 class="anchored" data-anchor-id="mean-decrease-in-the-gini-coefficient-from-a-random-forest">Mean Decrease in the Gini Coefficient from a Random Forest</h4>
<div id="d81a2b62" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X_unstandardized, y_unstandardized, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>rf <span class="op">=</span> RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">1000</span>, random_state<span class="op">=</span><span class="dv">42</span>, criterion<span class="op">=</span><span class="st">'gini'</span>)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>rf.fit(X_train, y_train)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract feature importances (Mean Decrease in Gini)</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>feature_importances <span class="op">=</span> rf.feature_importances_</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a DataFrame to hold the feature importances</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>features <span class="op">=</span> X_unstandardized.columns</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>importance_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Feature'</span>: features,</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Importance'</span>: feature_importances</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Sort the DataFrame by importance</span></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>importance_df <span class="op">=</span> importance_df.sort_values(by<span class="op">=</span><span class="st">'Importance'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>importance_df[<span class="st">"Importance_percentage"</span>] <span class="op">=</span> (importance_df[<span class="st">"Importance"</span>] <span class="op">/</span> importance_df[<span class="st">"Importance"</span>].<span class="bu">sum</span>()) <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>importance_df[<span class="st">"gini_percent"</span>] <span class="op">=</span> importance_df[<span class="st">"Importance_percentage"</span>].<span class="bu">round</span>(<span class="dv">2</span>)</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>gini_index <span class="op">=</span> importance_df[[<span class="st">"Feature"</span>, <span class="st">"gini_percent"</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="key-driver-analysis-and-interpretation" class="level3">
<h3 class="anchored" data-anchor-id="key-driver-analysis-and-interpretation">3. Key Driver Analysis and Interpretation</h3>
<div id="907fa978" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Merging all of the dataframes together</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="co">#Merging Pearsons with Standardized Linear Coefficient</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>merged_df <span class="op">=</span> pd.merge(pearson_corr_df, SLC_df, left_on <span class="op">=</span> <span class="st">'Features'</span>, right_on <span class="op">=</span> <span class="st">'Predictor'</span>, how <span class="op">=</span> <span class="st">'left'</span>)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co">#Merging on Shapley Percents</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>merged_df <span class="op">=</span> pd.merge(merged_df,shapley_df_short, left_on <span class="op">=</span> <span class="st">'Features'</span>, right_on <span class="op">=</span> <span class="st">'Feature'</span>, how <span class="op">=</span> <span class="st">'left'</span>)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="co">#Merging on Usefulness Percentages</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>merged_df <span class="op">=</span> pd.merge(merged_df,usefulness_df, left_on <span class="op">=</span> <span class="st">'Features'</span>, right_on <span class="op">=</span> <span class="st">'feature'</span>, how <span class="op">=</span> <span class="st">'left'</span>)</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="co">#Merging on Johnsons Percentages</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>merged_df <span class="op">=</span> pd.merge(merged_df,johnsons_df, left_on <span class="op">=</span> <span class="st">'Features'</span>, right_on <span class="op">=</span> <span class="st">'Feature'</span>, how <span class="op">=</span> <span class="st">'left'</span>)</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="co">#Merging on Gini Index %</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>merged_df <span class="op">=</span> pd.merge(merged_df,gini_index, left_on <span class="op">=</span> <span class="st">'Features'</span>, right_on <span class="op">=</span> <span class="st">'Feature'</span>, how <span class="op">=</span> <span class="st">'left'</span>)</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="co">#dropping redundant columns and setting the new index</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>merged_df.drop(columns<span class="op">=</span>[<span class="st">"Predictor"</span>, <span class="st">"Feature_x"</span>, <span class="st">"feature"</span>, <span class="st">"Feature_y"</span>, <span class="st">"Feature"</span>], inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>merged_df.set_index(<span class="st">'Features'</span>, inplace<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="76e84c67" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt </span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> textwrap <span class="im">import</span> wrap</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="88d4560d" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>column_aliases1 <span class="op">=</span> {</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Pearson_corr_%'</span>: <span class="st">'Pearson Correlations'</span>,</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'SLC_Percent of Total'</span>: <span class="st">' Regression Coeff.'</span>,</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Shapley_percent_Total'</span>: <span class="st">'Shapley Values'</span>,</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Usefulness %'</span>: <span class="st">'"Usefulness"'</span>,</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Johnsons Epsilon'</span>: <span class="st">"Johnson's Epsilon"</span>,</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'gini_percent'</span>: <span class="st">'Decrease - RF Gini'</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>merged_df.rename(columns<span class="op">=</span>column_aliases1, inplace<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="b5e1bf0c" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(merged_df)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Creating the heatmap</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>sns.heatmap(merged_df, annot<span class="op">=</span><span class="va">True</span>, cmap<span class="op">=</span><span class="st">'viridis'</span>, fmt<span class="op">=</span><span class="st">".2f"</span>)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">45</span>)</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Key Driver Analysis: Feature Percentages'</span>)</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>           Pearson Correlations   Regression Coeff.  Shapley Values  \
Features                                                              
trust                      13.3                24.8            19.0   
build                      10.0                 4.3             2.8   
differs                     9.6                 6.3             6.8   
easy                       11.1                 4.7             4.0   
appealing                  10.8                 7.3             4.8   
rewarding                  10.1                 1.1             0.6   
popular                     8.9                 3.6             0.7   
service                    13.0                18.9            23.6   
impact                     13.2                29.1            37.7   

           "Usefulness"  Johnson's Epsilon  Decrease - RF Gini  
Features                                                        
trust             31.52              11.39                9.98  
build              1.02              11.37               11.81  
differs            2.10              16.98               11.39  
easy               1.10              12.90               11.82  
appealing          2.71               7.46               10.91  
rewarding          0.06               8.31               12.45  
popular            0.78              10.88               12.88  
service           17.87              13.37                9.61  
impact            42.83               7.34                9.15  </code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-15-output-2.png" width="802" height="746" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Above is the table recreation showing the importance scores for various features across different driver analysis methods, each normalized as percentages. These methods help us understand which features most significantly affect the predictive power of a model. We can review each column and identify the most important features as determined by each respective method.</p>
<ul>
<li><p><strong>Pearson Correlations</strong>: This column reflects the linear correlation between each feature and our target variable, <code>satisfaction</code>. Higher values indicate a stronger linear relationship. Features like <code>trust</code>, <code>service</code>, and <code>impact</code> show relatively high correlation, suggesting these are important in a linear sense.</p></li>
<li><p><strong>Regression Coefficients</strong>: These scores are derived from a regression model, showing how much the target variable changes with a one-unit change in the feature, all else being equal. <code>Impact</code>, <code>trust</code>, and <code>service</code>, have higher coefficients, indicating significant influence on the model output.</p></li>
<li><p><strong>Shapley Values</strong>: This method distributes the prediction value among the features, attributing the impact of each feature on the outcome of the model. Again, <code>Impact</code>, <code>trust</code>, and <code>service</code> score high, underscoring their importance in contributing to model predictions.</p></li>
<li><p><strong>“Usefulness”</strong>: This value identifies impactful features via their respective change in the <span class="math inline">\(R^2\)</span> value. <code>Impact</code> and <code>trust</code> show exceptionally high values, highlighting their critical role.</p></li>
<li><p><strong>Johnson’s Epsilon</strong>: This metric likely measures the change in predictability when a feature is altered. “Differs”, “easy”, and “service” show higher values, suggesting these features significantly impact model predictability.</p></li>
<li><p><strong>Decrease - RF Gini</strong>: Derived from Random Forests, this shows the decrease in node impurity (Gini index) brought by each feature. “Popular”, “rewarding”, and “easy” have higher values, indicating their utility in improving model decisions through increased purity in node splits.</p></li>
</ul>
<p>Based on the heatmap and table created above, we see that there are three overall high impact features. <code>Impact</code>, <code>trust</code>, and <code>service</code> consistently show high importance across multiple metrics, suggesting they are crucial for accurate predictions. Features like <code>easy</code>, <code>differs</code>, and <code>appealing</code> exhibit moderate importance scores across various methods, indicating they play a secondary yet meaningful role in model predictions.<code>Rewarding</code> and <code>popular</code>, despite their roles, seem to have less influence compared to other features, particularly in metrics outside the Decrease - RF Gini. In this assignment, we were trying to recreate the table in slide 19. Despite not getting the exact same numbers, I did get the same ordering of important features.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>